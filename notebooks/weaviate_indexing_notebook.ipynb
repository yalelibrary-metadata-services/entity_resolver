{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Indexing and Retrieval with Weaviate v4\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this notebook, you will:\n",
    "- Set up and configure Weaviate vector database\n",
    "- Create collections optimized for library metadata\n",
    "- Index library catalog records with modern embeddings\n",
    "- Perform semantic similarity searches\n",
    "- Execute complex queries combining vector and keyword search\n",
    "- Apply these techniques to real entity resolution challenges\n",
    "\n",
    "## Why Vector Databases for Libraries?\n",
    "\n",
    "Traditional library catalogs rely on exact keyword matching and controlled vocabularies. But what if a researcher searches for \"musical compositions\" and we have records cataloged under \"symphonies,\" \"sonatas,\" or \"lieder\"? \n",
    "\n",
    "Vector databases like Weaviate solve this by understanding semantic meaning. They can find relevant records even when the exact terms don't match, opening up new possibilities for discovery and research.\n",
    "\n",
    "**Real Example**: A search for \"Viennese classical music\" could automatically surface records for Mozart, Beethoven, and Schubert, even if those exact terms don't appear in the catalog records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Environment Setup and Dependencies\n",
    "\n",
    "First, let's install the required packages and set up our environment. We'll use the latest Weaviate v4 Python client which provides significant improvements over previous versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T21:35:48.737737Z",
     "iopub.status.busy": "2025-06-30T21:35:48.737350Z",
     "iopub.status.idle": "2025-06-30T21:35:53.358017Z",
     "shell.execute_reply": "2025-06-30T21:35:53.357416Z",
     "shell.execute_reply.started": "2025-06-30T21:35:48.737706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: httpx in /Users/tt434/.pyenv/versions/dfrnt/lib/python3.11/site-packages (0.28.1)\n",
      "Collecting openai\n",
      "  Downloading openai-1.93.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio in /Users/tt434/.pyenv/versions/dfrnt/lib/python3.11/site-packages (from httpx) (4.0.0)\n",
      "Requirement already satisfied: certifi in /Users/tt434/.pyenv/versions/dfrnt/lib/python3.11/site-packages (from httpx) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/tt434/.pyenv/versions/dfrnt/lib/python3.11/site-packages (from httpx) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/tt434/.pyenv/versions/dfrnt/lib/python3.11/site-packages (from httpx) (3.4)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/tt434/.pyenv/versions/dfrnt/lib/python3.11/site-packages (from httpcore==1.*->httpx) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/tt434/.pyenv/versions/dfrnt/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/tt434/.pyenv/versions/dfrnt/lib/python3.11/site-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/tt434/.pyenv/versions/dfrnt/lib/python3.11/site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /Users/tt434/.pyenv/versions/dfrnt/lib/python3.11/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/tt434/.pyenv/versions/dfrnt/lib/python3.11/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/tt434/.pyenv/versions/dfrnt/lib/python3.11/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/tt434/.pyenv/versions/dfrnt/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/tt434/.pyenv/versions/dfrnt/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/tt434/.pyenv/versions/dfrnt/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Downloading openai-1.93.0-py3-none-any.whl (755 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m755.0/755.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "Successfully installed openai-1.93.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install httpx openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T21:35:58.127177Z",
     "iopub.status.busy": "2025-06-30T21:35:58.126439Z",
     "iopub.status.idle": "2025-06-30T21:35:59.476727Z",
     "shell.execute_reply": "2025-06-30T21:35:59.476220Z",
     "shell.execute_reply.started": "2025-06-30T21:35:58.127123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpcore                      1.0.9\n",
      "httpx                         0.28.1\n",
      "langchain-openai              0.2.2\n",
      "openai                        1.93.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep -E \"(openai|httpx|httpcore)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T21:36:04.313955Z",
     "iopub.status.busy": "2025-06-30T21:36:04.313441Z",
     "iopub.status.idle": "2025-06-30T21:36:04.596677Z",
     "shell.execute_reply": "2025-06-30T21:36:04.595928Z",
     "shell.execute_reply.started": "2025-06-30T21:36:04.313917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: 4.4.0 not found\n",
      "âœ… Environment setup complete!\n",
      "ğŸ“¦ Weaviate client version: 4.8.0\n"
     ]
    }
   ],
   "source": [
    "# Install required packages for this workshop\n",
    "!pip install weaviate-client>=4.4.0 openai pandas numpy matplotlib seaborn python-dotenv\n",
    "\n",
    "# Import libraries\n",
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "from weaviate.classes.config import Property, DataType, Configure\n",
    "from weaviate.classes.query import MetadataQuery\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Any, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables (create a .env file with your API keys)\n",
    "load_dotenv()\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"âœ… Environment setup complete!\")\n",
    "print(f\"ğŸ“¦ Weaviate client version: {weaviate.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Starting Weaviate and Client Connection\n",
    "\n",
    "We'll start with a local Weaviate instance using Docker. This gives us full control and eliminates API costs during development.\n",
    "\n",
    "**Note**: If you don't have Docker installed, you can use Weaviate Cloud Services (WCS) instead by modifying the connection parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T21:40:53.983069Z",
     "iopub.status.busy": "2025-06-30T21:40:53.982717Z",
     "iopub.status.idle": "2025-06-30T21:40:54.213449Z",
     "shell.execute_reply": "2025-06-30T21:40:54.212990Z",
     "shell.execute_reply.started": "2025-06-30T21:40:53.983027Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully connected to Weaviate at http://localhost:8080\n",
      "ğŸ“Š Weaviate version: 1.30.0-rc.0\n",
      "\n",
      "ğŸ” Current collections in Weaviate: 7\n",
      "  - ConceptScheme\n",
      "  - ClassificationScheme\n",
      "  - LibraryCatalog\n",
      "  - FineTunedConcepts\n",
      "  - Document\n",
      "  - MultilingualDocument\n",
      "  - EntityString\n"
     ]
    }
   ],
   "source": [
    "# First, let's start Weaviate using Docker\n",
    "# Run this in your terminal before executing this notebook:\n",
    "# docker run -d --name weaviate-workshop \\\n",
    "#   -p 8080:8080 -p 50051:50051 \\\n",
    "#   -e QUERY_DEFAULTS_LIMIT=25 \\\n",
    "#   -e AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true \\\n",
    "#   -e PERSISTENCE_DATA_PATH='/var/lib/weaviate' \\\n",
    "#   -e DEFAULT_VECTORIZER_MODULE='none' \\\n",
    "#   -e CLUSTER_HOSTNAME='node1' \\\n",
    "#   semitechnologies/weaviate:1.25.0\n",
    "\n",
    "# Connect to local Weaviate instance\n",
    "def connect_to_weaviate(host: str = \"localhost\", port: int = 8080, secure: bool = False) -> weaviate.WeaviateClient:\n",
    "    \"\"\"Connect to Weaviate instance with proper error handling.\"\"\"\n",
    "    try:\n",
    "        # Create connection URL\n",
    "        protocol = \"https\" if secure else \"http\"\n",
    "        url = f\"{protocol}://{host}:{port}\"\n",
    "        \n",
    "        # Connect using v4 client syntax\n",
    "        weaviate_client = weaviate.connect_to_local(\n",
    "            host=host,\n",
    "            port=port,\n",
    "            grpc_port=50051,  # gRPC port for faster operations            \n",
    "        )\n",
    "        \n",
    "        # Test the connection\n",
    "        if weaviate_client.is_ready():\n",
    "            print(f\"âœ… Successfully connected to Weaviate at {url}\")\n",
    "            \n",
    "            # Get cluster information\n",
    "            meta = weaviate_client.get_meta()\n",
    "            print(f\"ğŸ“Š Weaviate version: {meta.get('version', 'Unknown')}\")\n",
    "            \n",
    "            return weaviate_client\n",
    "        else:\n",
    "            raise ConnectionError(\"Weaviate is not ready\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to connect to Weaviate: {e}\")\n",
    "        print(\"\\nğŸ’¡ Troubleshooting tips:\")\n",
    "        print(\"   1. Make sure Docker is running\")\n",
    "        print(\"   2. Start Weaviate with the Docker command provided above\")\n",
    "        print(\"   3. Wait 30-60 seconds for Weaviate to fully start\")\n",
    "        print(\"   4. Check that port 8080 is not in use by another service\")\n",
    "        raise\n",
    "\n",
    "# Connect to Weaviate\n",
    "weaviate_client = connect_to_weaviate()\n",
    "\n",
    "# Verify connection with some basic info\n",
    "print(f\"\\nğŸ” Current collections in Weaviate: {len(weaviate_client.collections.list_all())}\")\n",
    "for collection_name in weaviate_client.collections.list_all():\n",
    "    print(f\"  - {collection_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Designing Our Library Collection Schema\n",
    "\n",
    "Now we'll create a collection specifically designed for library catalog records. This schema will capture the essential metadata fields while optimizing for semantic search.\n",
    "\n",
    "Think of this as designing the \"database table\" structure, but optimized for vector similarity rather than traditional relational queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T21:40:57.772659Z",
     "iopub.status.busy": "2025-06-30T21:40:57.772147Z",
     "iopub.status.idle": "2025-06-30T21:40:57.986787Z",
     "shell.execute_reply": "2025-06-30T21:40:57.986024Z",
     "shell.execute_reply.started": "2025-06-30T21:40:57.772627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—‘ï¸  Deleting existing 'LibraryCatalog' collection\n",
      "âœ… Created collection 'LibraryCatalog' successfully\n",
      "ğŸ“‹ Properties defined: 9\n",
      "\n",
      "ğŸ“Š Collection Schema:\n",
      "  â€¢ personId: Unique identifier for the person/entity\n",
      "  â€¢ person: Person name (e.g., 'Schubert, Franz, 1797-1828')\n",
      "  â€¢ title: Work title\n",
      "  â€¢ roles: Person's role (Composer, Contributor, etc.)\n",
      "  â€¢ subjects: Subject headings and topics\n",
      "  â€¢ provision: Publication information\n",
      "  â€¢ composite: Full composite record for embedding\n",
      "  â€¢ classification: Hierarchical classification (e.g., 'Music and Sound Arts')\n",
      "  â€¢ recordId: Original catalog record ID\n",
      "\n",
      "ğŸ¯ Total collections now: 7\n",
      "ğŸ“š Ready to work with 'LibraryCatalog' collection\n"
     ]
    }
   ],
   "source": [
    "# Define our library catalog collection schema\n",
    "COLLECTION_NAME = \"LibraryCatalog\"\n",
    "\n",
    "def create_library_collection(weaviate_client: weaviate.WeaviateClient) -> bool:\n",
    "    \"\"\"Create a collection optimized for library catalog records.\"\"\"\n",
    "    \n",
    "    # Delete existing collection if it exists (for clean slate)\n",
    "    if weaviate_client.collections.exists(COLLECTION_NAME):\n",
    "        print(f\"ğŸ—‘ï¸  Deleting existing '{COLLECTION_NAME}' collection\")\n",
    "        weaviate_client.collections.delete(COLLECTION_NAME)\n",
    "    \n",
    "    try:\n",
    "        # Define properties for our library records\n",
    "        # Each property maps to a field in our MARC/catalog data\n",
    "        properties = [\n",
    "            Property(\n",
    "                name=\"personId\",\n",
    "                data_type=DataType.TEXT,\n",
    "                description=\"Unique identifier for the person/entity\"\n",
    "            ),\n",
    "            Property(\n",
    "                name=\"person\",\n",
    "                data_type=DataType.TEXT,\n",
    "                description=\"Person name (e.g., 'Schubert, Franz, 1797-1828')\"\n",
    "            ),\n",
    "            Property(\n",
    "                name=\"title\",\n",
    "                data_type=DataType.TEXT,\n",
    "                description=\"Work title\"\n",
    "            ),\n",
    "            Property(\n",
    "                name=\"roles\",\n",
    "                data_type=DataType.TEXT,\n",
    "                description=\"Person's role (Composer, Contributor, etc.)\"\n",
    "            ),\n",
    "            Property(\n",
    "                name=\"subjects\",\n",
    "                data_type=DataType.TEXT,\n",
    "                description=\"Subject headings and topics\"\n",
    "            ),\n",
    "            Property(\n",
    "                name=\"provision\",\n",
    "                data_type=DataType.TEXT,\n",
    "                description=\"Publication information\"\n",
    "            ),\n",
    "            Property(\n",
    "                name=\"composite\",\n",
    "                data_type=DataType.TEXT,\n",
    "                description=\"Full composite record for embedding\"\n",
    "            ),\n",
    "            Property(\n",
    "                name=\"classification\",\n",
    "                data_type=DataType.TEXT,\n",
    "                description=\"Hierarchical classification (e.g., 'Music and Sound Arts')\"\n",
    "            ),\n",
    "            Property(\n",
    "                name=\"recordId\",\n",
    "                data_type=DataType.TEXT,\n",
    "                description=\"Original catalog record ID\"\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Create the collection with manual vectorization\n",
    "        # We'll provide our own embeddings rather than using Weaviate's built-in vectorizers\n",
    "        collection = weaviate_client.collections.create(\n",
    "            name=COLLECTION_NAME,\n",
    "            properties=properties,\n",
    "            # Configure for manual vector management\n",
    "            vectorizer_config=Configure.Vectorizer.none(),\n",
    "            # Use HNSW index for fast approximate nearest neighbor search\n",
    "            vector_index_config=Configure.VectorIndex.hnsw(\n",
    "                distance_metric=wvc.config.VectorDistances.COSINE,  # Use cosine similarity\n",
    "                ef_construction=128,  # Higher = better quality, slower indexing\n",
    "                max_connections=64   # Higher = better search quality, more memory\n",
    "            ),\n",
    "            description=\"Yale Library catalog records with semantic embeddings\"\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Created collection '{COLLECTION_NAME}' successfully\")\n",
    "        print(f\"ğŸ“‹ Properties defined: {len(properties)}\")\n",
    "        \n",
    "        # Display the schema for verification\n",
    "        print(\"\\nğŸ“Š Collection Schema:\")\n",
    "        for prop in properties:\n",
    "            print(f\"  â€¢ {prop.name}: {prop.description}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to create collection: {e}\")\n",
    "        return False\n",
    "\n",
    "# Create our library collection\n",
    "success = create_library_collection(weaviate_client)\n",
    "\n",
    "if success:\n",
    "    # Verify the collection was created\n",
    "    collections = weaviate_client.collections.list_all()\n",
    "    print(f\"\\nğŸ¯ Total collections now: {len(collections)}\")\n",
    "    \n",
    "    # Get a reference to our collection for future operations\n",
    "    library_collection = weaviate_client.collections.get(COLLECTION_NAME)\n",
    "    print(f\"ğŸ“š Ready to work with '{COLLECTION_NAME}' collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Preparing Sample Library Data\n",
    "\n",
    "Let's create sample library catalog records that represent the diversity of an academic library collection. We'll include our Franz Schubert examples plus records from various domains to demonstrate semantic search capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T21:41:12.956857Z",
     "iopub.status.busy": "2025-06-30T21:41:12.956171Z",
     "iopub.status.idle": "2025-06-30T21:41:12.970856Z",
     "shell.execute_reply": "2025-06-30T21:41:12.969818Z",
     "shell.execute_reply.started": "2025-06-30T21:41:12.956821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š Created 9 sample library records\n",
      "\n",
      "ğŸ“Š Records by classification:\n",
      "  â€¢ Music and Sound Arts: 4 records\n",
      "  â€¢ Documentary and Technical Arts: 1 records\n",
      "  â€¢ Visual Arts: 1 records\n",
      "  â€¢ History and Culture: 1 records\n",
      "  â€¢ Social Sciences: 1 records\n",
      "  â€¢ Literature and Narrative Arts: 1 records\n",
      "\n",
      "ğŸ” Example record structure:\n",
      "  personId: 53001#Agent700-1\n",
      "  person: Schubert, Franz, 1797-1828\n",
      "  title: Symphony no. 8 in B minor, D. 759 \"Unfinished\"\n",
      "  roles: Composer\n",
      "  subjects: Symphonies; Classical music; Romantic period music\n",
      "  provision: Vienna: Universal Edition, 1978\n",
      "  composite: Title: Symphony no. 8 in B minor, D. 759 \"Unfinished\" Subjects: Symphonies; Classical music; Romantic period music Provision information: Vienna: Universal Edition, 1978\n",
      "  classification: Music and Sound Arts\n",
      "  recordId: 53001\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive sample library data\n",
    "def create_sample_library_data() -> List[Dict[str, Any]]:\n",
    "    \"\"\"Generate sample library catalog records for demonstration.\"\"\"\n",
    "    \n",
    "    sample_records = [\n",
    "        # Franz Schubert - Composer (1797-1828)\n",
    "        {\n",
    "            \"personId\": \"53001#Agent700-1\",\n",
    "            \"person\": \"Schubert, Franz, 1797-1828\",\n",
    "            \"title\": \"Symphony no. 8 in B minor, D. 759 \\\"Unfinished\\\"\",\n",
    "            \"roles\": \"Composer\",\n",
    "            \"subjects\": \"Symphonies; Classical music; Romantic period music\",\n",
    "            \"provision\": \"Vienna: Universal Edition, 1978\",\n",
    "            \"composite\": \"Title: Symphony no. 8 in B minor, D. 759 \\\"Unfinished\\\" Subjects: Symphonies; Classical music; Romantic period music Provision information: Vienna: Universal Edition, 1978\",\n",
    "            \"classification\": \"Music and Sound Arts\",\n",
    "            \"recordId\": \"53001\"\n",
    "        },\n",
    "        {\n",
    "            \"personId\": \"53001#Agent700-2\",\n",
    "            \"person\": \"Schubert, Franz, 1797-1828\",\n",
    "            \"title\": \"Gretchen am Spinnrade, D. 118\",\n",
    "            \"roles\": \"Composer\",\n",
    "            \"subjects\": \"Songs; Lieder; German songs; Voice and piano music\",\n",
    "            \"provision\": \"Leipzig: C. F. Peters, 1885\",\n",
    "            \"composite\": \"Title: Gretchen am Spinnrade, D. 118 Subjects: Songs; Lieder; German songs; Voice and piano music Provision information: Leipzig: C. F. Peters, 1885\",\n",
    "            \"classification\": \"Music and Sound Arts\",\n",
    "            \"recordId\": \"53002\"\n",
    "        },\n",
    "        \n",
    "        # Franz August Schubert - Artist (1806-1893)\n",
    "        {\n",
    "            \"personId\": \"53144#Agent700-22\",\n",
    "            \"person\": \"Schubert, Franz August, 1806-1893\",\n",
    "            \"title\": \"ArchÃ¤ologie und Photographie: fÃ¼nfzig Beispiele zur Geschichte und Methode\",\n",
    "            \"roles\": \"Contributor\",\n",
    "            \"subjects\": \"Photography in archaeology; Archaeological illustration; Scientific photography\",\n",
    "            \"provision\": \"Mainz: P. von Zabern, 1978\",\n",
    "            \"composite\": \"Title: ArchÃ¤ologie und Photographie: fÃ¼nfzig Beispiele zur Geschichte und Methode Subjects: Photography in archaeology; Archaeological illustration; Scientific photography Provision information: Mainz: P. von Zabern, 1978\",\n",
    "            \"classification\": \"Documentary and Technical Arts\",\n",
    "            \"recordId\": \"53144\"\n",
    "        },\n",
    "        {\n",
    "            \"personId\": \"53144#Agent700-23\",\n",
    "            \"person\": \"Schubert, Franz August, 1806-1893\",\n",
    "            \"title\": \"Dessauer KÃ¼nstler des 19. Jahrhunderts\",\n",
    "            \"roles\": \"Artist\",\n",
    "            \"subjects\": \"German artists; 19th century art; Regional art history; Portrait painting\",\n",
    "            \"provision\": \"Dessau: Anhaltische Verlagsgesellschaft, 1925\",\n",
    "            \"composite\": \"Title: Dessauer KÃ¼nstler des 19. Jahrhunderts Subjects: German artists; 19th century art; Regional art history; Portrait painting Provision information: Dessau: Anhaltische Verlagsgesellschaft, 1925\",\n",
    "            \"classification\": \"Visual Arts\",\n",
    "            \"recordId\": \"53145\"\n",
    "        },\n",
    "        \n",
    "        # Other composers for context\n",
    "        {\n",
    "            \"personId\": \"12345#Agent700-5\",\n",
    "            \"person\": \"Mozart, Wolfgang Amadeus, 1756-1791\",\n",
    "            \"title\": \"Piano Sonata No. 11 in A major, K. 331\",\n",
    "            \"roles\": \"Composer\",\n",
    "            \"subjects\": \"Piano music; Classical period; Sonatas\",\n",
    "            \"provision\": \"Vienna: Artaria, 1784\",\n",
    "            \"composite\": \"Title: Piano Sonata No. 11 in A major, K. 331 Subjects: Piano music; Classical period; Sonatas Provision information: Vienna: Artaria, 1784\",\n",
    "            \"classification\": \"Music and Sound Arts\",\n",
    "            \"recordId\": \"12345\"\n",
    "        },\n",
    "        {\n",
    "            \"personId\": \"67890#Agent700-8\",\n",
    "            \"person\": \"Beethoven, Ludwig van, 1770-1827\",\n",
    "            \"title\": \"Symphony No. 9 in D minor, Op. 125 \\\"Choral\\\"\",\n",
    "            \"roles\": \"Composer\",\n",
    "            \"subjects\": \"Symphonies; Choral symphonies; Classical music; Romantic music\",\n",
    "            \"provision\": \"Mainz: B. Schott's SÃ¶hne, 1826\",\n",
    "            \"composite\": \"Title: Symphony No. 9 in D minor, Op. 125 \\\"Choral\\\" Subjects: Symphonies; Choral symphonies; Classical music; Romantic music Provision information: Mainz: B. Schott's SÃ¶hne, 1826\",\n",
    "            \"classification\": \"Music and Sound Arts\",\n",
    "            \"recordId\": \"67890\"\n",
    "        },\n",
    "        \n",
    "        # Archaeology and Art records for domain contrast\n",
    "        {\n",
    "            \"personId\": \"78901#Agent700-12\",\n",
    "            \"person\": \"Winkelmann, Johann Joachim, 1717-1768\",\n",
    "            \"title\": \"Geschichte der Kunst des Alterthums\",\n",
    "            \"roles\": \"Author\",\n",
    "            \"subjects\": \"Art history; Ancient art; Classical archaeology; Greek art; Roman art\",\n",
    "            \"provision\": \"Dresden: Walther, 1764\",\n",
    "            \"composite\": \"Title: Geschichte der Kunst des Alterthums Subjects: Art history; Ancient art; Classical archaeology; Greek art; Roman art Provision information: Dresden: Walther, 1764\",\n",
    "            \"classification\": \"History and Culture\",\n",
    "            \"recordId\": \"78901\"\n",
    "        },\n",
    "        {\n",
    "            \"personId\": \"89012#Agent700-15\",\n",
    "            \"person\": \"Wheeler, Mortimer, 1890-1976\",\n",
    "            \"title\": \"Archaeology from the Earth\",\n",
    "            \"roles\": \"Author\",\n",
    "            \"subjects\": \"Archaeological methods; Excavation techniques; Field archaeology; Stratigraphy\",\n",
    "            \"provision\": \"Oxford: Clarendon Press, 1954\",\n",
    "            \"composite\": \"Title: Archaeology from the Earth Subjects: Archaeological methods; Excavation techniques; Field archaeology; Stratigraphy Provision information: Oxford: Clarendon Press, 1954\",\n",
    "            \"classification\": \"Social Sciences\",\n",
    "            \"recordId\": \"89012\"\n",
    "        },\n",
    "        \n",
    "        # Literature for additional domain diversity\n",
    "        {\n",
    "            \"personId\": \"34567#Agent700-20\",\n",
    "            \"person\": \"Goethe, Johann Wolfgang von, 1749-1832\",\n",
    "            \"title\": \"Faust: eine TragÃ¶die\",\n",
    "            \"roles\": \"Author\",\n",
    "            \"subjects\": \"German literature; Drama; Romanticism; Philosophy in literature\",\n",
    "            \"provision\": \"TÃ¼bingen: Cotta, 1808\",\n",
    "            \"composite\": \"Title: Faust: eine TragÃ¶die Subjects: German literature; Drama; Romanticism; Philosophy in literature Provision information: TÃ¼bingen: Cotta, 1808\",\n",
    "            \"classification\": \"Literature and Narrative Arts\",\n",
    "            \"recordId\": \"34567\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return sample_records\n",
    "\n",
    "# Generate our sample data\n",
    "sample_data = create_sample_library_data()\n",
    "\n",
    "print(f\"ğŸ“š Created {len(sample_data)} sample library records\")\n",
    "print(\"\\nğŸ“Š Records by classification:\")\n",
    "\n",
    "# Count records by classification\n",
    "classification_counts = {}\n",
    "for record in sample_data:\n",
    "    classification = record[\"classification\"]\n",
    "    classification_counts[classification] = classification_counts.get(classification, 0) + 1\n",
    "\n",
    "for classification, count in classification_counts.items():\n",
    "    print(f\"  â€¢ {classification}: {count} records\")\n",
    "\n",
    "# Display first record as example\n",
    "print(\"\\nğŸ” Example record structure:\")\n",
    "for key, value in sample_data[0].items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Generating Embeddings with OpenAI\n",
    "\n",
    "Now we need to convert our text records into vector embeddings. We'll use OpenAI's text-embedding-3-small model, which provides excellent performance for semantic search tasks.\n",
    "\n",
    "**Note**: You'll need an OpenAI API key for this section. Add it to your `.env` file as `OPENAI_API_KEY=your_key_here`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T21:30:02.058415Z",
     "iopub.status.busy": "2025-06-30T21:30:02.057853Z",
     "iopub.status.idle": "2025-06-30T21:30:03.401985Z",
     "shell.execute_reply": "2025-06-30T21:30:03.401238Z",
     "shell.execute_reply.started": "2025-06-30T21:30:02.058376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: openai 1.12.0\n",
      "Uninstalling openai-1.12.0:\n",
      "  Successfully uninstalled openai-1.12.0\n",
      "Found existing installation: httpx 0.25.2\n",
      "Uninstalling httpx-0.25.2:\n",
      "  Successfully uninstalled httpx-0.25.2\n",
      "Found existing installation: httpcore 1.0.9\n",
      "Uninstalling httpcore-1.0.9:\n",
      "  Successfully uninstalled httpcore-1.0.9\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall openai httpx httpcore -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T21:30:12.000438Z",
     "iopub.status.busy": "2025-06-30T21:30:11.999920Z",
     "iopub.status.idle": "2025-06-30T21:30:15.289769Z",
     "shell.execute_reply": "2025-06-30T21:30:15.289109Z",
     "shell.execute_reply.started": "2025-06-30T21:30:12.000402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: 1.3.0 not found\n"
     ]
    }
   ],
   "source": [
    "!pip install openai>=1.3.0 httpx httpcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T21:49:54.041638Z",
     "iopub.status.busy": "2025-06-30T21:49:54.040052Z",
     "iopub.status.idle": "2025-06-30T21:49:54.383622Z",
     "shell.execute_reply": "2025-06-30T21:49:54.362248Z",
     "shell.execute_reply.started": "2025-06-30T21:49:54.041598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OpenAI client created successfully\n",
      "âœ… Generated 9 real embeddings using 384 tokens\n",
      "ğŸ”— Successfully attached vectors to 9 records\n",
      "ğŸ“š Ready to proceed with Weaviate indexing!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from openai import OpenAI\n",
    "\n",
    "# Simple, direct OpenAI client setup following your working pattern\n",
    "def setup_openai_client():\n",
    "    \"\"\"Create OpenAI client using the exact pattern from your working code.\"\"\"\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    \n",
    "    if not api_key:\n",
    "        print(\"âš ï¸  No OpenAI API key found\")\n",
    "        return None, False\n",
    "    \n",
    "    try:\n",
    "        # This is exactly how you do it in your working code\n",
    "        openai_client = OpenAI(api_key=api_key)\n",
    "        print(\"âœ… OpenAI client created successfully\")\n",
    "        return openai_client, True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Client creation failed: {e}\")\n",
    "        return None, False\n",
    "\n",
    "def get_embeddings(texts: List[str], openai_client=None, model: str = \"text-embedding-3-small\") -> List[List[float]]:\n",
    "    \"\"\"Generate embeddings using your proven API call pattern.\"\"\"\n",
    "    \n",
    "    if openai_client is None:\n",
    "        return create_dummy_embeddings(texts)\n",
    "    \n",
    "    try:\n",
    "        # This follows your exact working pattern from embedding_and_indexing.py\n",
    "        response = openai_client.embeddings.create(\n",
    "            model=model,\n",
    "            input=texts\n",
    "        )\n",
    "        \n",
    "        # Extract embeddings exactly like your working code\n",
    "        embeddings = []\n",
    "        for embedding_data in response.data:\n",
    "            embedding = np.array(embedding_data.embedding, dtype=np.float32)\n",
    "            embeddings.append(embedding.tolist())  # Convert to list for consistency\n",
    "        \n",
    "        # Get token count like your working code\n",
    "        token_count = response.usage.total_tokens\n",
    "        \n",
    "        print(f\"âœ… Generated {len(embeddings)} real embeddings using {token_count} tokens\")\n",
    "        return embeddings\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  API call failed: {e}\")\n",
    "        print(\"Falling back to dummy embeddings...\")\n",
    "        return create_dummy_embeddings(texts)\n",
    "\n",
    "def create_dummy_embeddings(texts: List[str]) -> List[List[float]]:\n",
    "    \"\"\"Create educational dummy embeddings with realistic patterns.\"\"\"\n",
    "    print(\"ğŸ“ Creating dummy embeddings...\")\n",
    "    \n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        # Deterministic embeddings based on text content\n",
    "        np.random.seed(hash(text) % 2147483647)\n",
    "        embedding = np.random.normal(0, 0.1, 1536).tolist()\n",
    "        \n",
    "        # Add semantic clustering based on content\n",
    "        text_lower = text.lower()\n",
    "        if any(word in text_lower for word in [\"music\", \"symphony\", \"composer\"]):\n",
    "            for i in range(0, 100):\n",
    "                embedding[i] += 0.4\n",
    "        elif any(word in text_lower for word in [\"archaeology\", \"photography\", \"art\"]):\n",
    "            for i in range(200, 300):\n",
    "                embedding[i] += 0.4\n",
    "        \n",
    "        embeddings.append(embedding)\n",
    "    \n",
    "    print(f\"ğŸ“Š Created {len(embeddings)} dummy embeddings\")\n",
    "    return embeddings\n",
    "\n",
    "# Execute the setup using your proven approach\n",
    "openai_client, has_real_api = setup_openai_client()\n",
    "\n",
    "# Generate embeddings for your data\n",
    "texts_to_embed = [record[\"composite\"] for record in sample_data]\n",
    "embeddings = get_embeddings(texts_to_embed, openai_client)\n",
    "\n",
    "# Attach to records\n",
    "for i, record in enumerate(sample_data):\n",
    "    record[\"vector\"] = embeddings[i]\n",
    "\n",
    "print(f\"ğŸ”— Successfully attached vectors to {len(sample_data)} records\")\n",
    "print(\"ğŸ“š Ready to proceed with Weaviate indexing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Indexing Records in Weaviate\n",
    "\n",
    "Now comes the exciting part - loading our embedded records into Weaviate! This is where the magic happens: Weaviate will build an efficient index structure that allows for fast similarity searches across our entire collection.\n",
    "\n",
    "The HNSW (Hierarchical Navigable Small World) algorithm creates a graph structure that can find similar vectors in logarithmic time, even with millions of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T21:49:59.633548Z",
     "iopub.status.busy": "2025-06-30T21:49:59.632456Z",
     "iopub.status.idle": "2025-06-30T21:49:59.683924Z",
     "shell.execute_reply": "2025-06-30T21:49:59.683393Z",
     "shell.execute_reply.started": "2025-06-30T21:49:59.633468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¤ Starting to index 9 records...\n",
      "  ğŸ“‹ Prepared 2/9 records\n",
      "  ğŸ“‹ Prepared 4/9 records\n",
      "  ğŸ“‹ Prepared 6/9 records\n",
      "  ğŸ“‹ Prepared 8/9 records\n",
      "\n",
      "ğŸš€ Inserting 9 records into Weaviate...\n",
      "âœ… Successfully indexed 9/9 records\n",
      "ğŸ“Š Total objects in collection: 9\n",
      "\n",
      "ğŸ‰ Indexing completed successfully!\n",
      "ğŸ“š Your library collection is now ready for semantic search\n",
      "\n",
      "ğŸ” Sample indexed record:\n",
      "  UUID: 1099f26d-99f1-5080-8efd-ede20ae10695\n",
      "  Person: Winkelmann, Johann Joachim, 1717-1768\n",
      "  Title: Geschichte der Kunst des Alterthums\n",
      "  Classification: History and Culture\n",
      "  Vector dimension: N/A\n"
     ]
    }
   ],
   "source": [
    "from weaviate.classes.data import DataObject\n",
    "from weaviate.util import generate_uuid5\n",
    "\n",
    "def index_library_records(client: weaviate.WeaviateClient, records: List[Dict[str, Any]]) -> bool:\n",
    "    \"\"\"\n",
    "    Index library records into Weaviate with their embeddings.\n",
    "    \n",
    "    Args:\n",
    "        client: Weaviate client instance\n",
    "        records: List of library records with embeddings\n",
    "    \n",
    "    Returns:\n",
    "        True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get our collection\n",
    "        collection = weaviate_client.collections.get(COLLECTION_NAME)\n",
    "        \n",
    "        print(f\"ğŸ“¤ Starting to index {len(records)} records...\")\n",
    "        \n",
    "        # Prepare data objects for batch insertion\n",
    "        data_objects = []\n",
    "        \n",
    "        for i, record in enumerate(records):\n",
    "            # Extract the vector (embedding)\n",
    "            vector = record.pop(\"vector\")  # Remove vector from properties\n",
    "            \n",
    "            # Generate a consistent UUID based on the record ID\n",
    "            # This ensures we can update the same record later if needed\n",
    "            uuid = generate_uuid5(record[\"recordId\"], \"LibraryRecord\")\n",
    "            \n",
    "            # Create data object\n",
    "            data_object = DataObject(\n",
    "                properties=record,  # All the metadata fields\n",
    "                vector=vector,      # The embedding vector\n",
    "                uuid=uuid          # Consistent UUID\n",
    "            )\n",
    "            \n",
    "            data_objects.append(data_object)\n",
    "            \n",
    "            # Progress indicator\n",
    "            if (i + 1) % 2 == 0:\n",
    "                print(f\"  ğŸ“‹ Prepared {i + 1}/{len(records)} records\")\n",
    "        \n",
    "        # Batch insert all records\n",
    "        print(f\"\\nğŸš€ Inserting {len(data_objects)} records into Weaviate...\")\n",
    "        \n",
    "        # Use batch insertion for efficiency\n",
    "        response = collection.data.insert_many(data_objects)\n",
    "        \n",
    "        # Check for any errors\n",
    "        if response.has_errors:\n",
    "            print(f\"âš ï¸  Some records had errors:\")\n",
    "            for i, error in enumerate(response.errors):\n",
    "                if error:\n",
    "                    print(f\"  Record {i}: {error}\")\n",
    "        \n",
    "        successful_inserts = len([r for r in response.uuids if r is not None])\n",
    "        print(f\"âœ… Successfully indexed {successful_inserts}/{len(records)} records\")\n",
    "        \n",
    "        # Verify the data was inserted\n",
    "        total_objects = collection.aggregate.over_all(total_count=True).total_count\n",
    "        print(f\"ğŸ“Š Total objects in collection: {total_objects}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error indexing records: {e}\")\n",
    "        return False\n",
    "\n",
    "# Index our sample records\n",
    "success = index_library_records(weaviate_client, sample_data)\n",
    "\n",
    "if success:\n",
    "    print(\"\\nğŸ‰ Indexing completed successfully!\")\n",
    "    print(\"ğŸ“š Your library collection is now ready for semantic search\")\n",
    "    \n",
    "    # Quick verification: let's see what's in our collection\n",
    "    collection = weaviate_client.collections.get(COLLECTION_NAME)\n",
    "    \n",
    "    # Get a sample record to verify structure\n",
    "    sample_result = collection.query.fetch_objects(limit=1)\n",
    "    \n",
    "    if sample_result.objects:\n",
    "        sample_object = sample_result.objects[0]\n",
    "        print(f\"\\nğŸ” Sample indexed record:\")\n",
    "        print(f\"  UUID: {sample_object.uuid}\")\n",
    "        print(f\"  Person: {sample_object.properties.get('person', 'N/A')}\")\n",
    "        print(f\"  Title: {sample_object.properties.get('title', 'N/A')}\")\n",
    "        print(f\"  Classification: {sample_object.properties.get('classification', 'N/A')}\")\n",
    "        print(f\"  Vector dimension: {len(sample_object.vector) if sample_object.vector else 'N/A'}\")\n",
    "else:\n",
    "    print(\"âŒ Indexing failed. Please check the error messages above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Basic Semantic Search Queries\n",
    "\n",
    "Now for the exciting part - let's search our library collection using semantic similarity! We'll start with basic vector searches and then explore more sophisticated querying techniques.\n",
    "\n",
    "Vector search finds records that are semantically similar to your query, even if they don't contain the exact same words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T21:50:06.010086Z",
     "iopub.status.busy": "2025-06-30T21:50:06.009787Z",
     "iopub.status.idle": "2025-06-30T21:50:08.579324Z",
     "shell.execute_reply": "2025-06-30T21:50:08.578383Z",
     "shell.execute_reply.started": "2025-06-30T21:50:06.010065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Searching for: 'classical music composer symphonies'\n",
      "ğŸ“ Creating dummy embeddings...\n",
      "ğŸ“Š Created 1 dummy embeddings\n",
      "\n",
      "ğŸ“Š Search Results for: 'classical music composer symphonies'\n",
      "============================================================\n",
      "\n",
      "1. ğŸ“š Winkelmann, Johann Joachim, 1717-1768\n",
      "   ğŸ“– Title: Geschichte der Kunst des Alterthums\n",
      "   ğŸ·ï¸  Classification: History and Culture\n",
      "   ğŸ”– Subjects: Art history; Ancient art; Classical archaeology; Greek art; Roman art\n",
      "   ğŸ“ Similarity: 6.3%\n",
      "\n",
      "2. ğŸ“š Schubert, Franz August, 1806-1893\n",
      "   ğŸ“– Title: ArchÃ¤ologie und Photographie: fÃ¼nfzig Beispiele zur Geschichte und Methode\n",
      "   ğŸ·ï¸  Classification: Documentary and Technical Arts\n",
      "   ğŸ”– Subjects: Photography in archaeology; Archaeological illustration; Scientific photography\n",
      "   ğŸ“ Similarity: 5.6%\n",
      "\n",
      "3. ğŸ“š Schubert, Franz August, 1806-1893\n",
      "   ğŸ“– Title: Dessauer KÃ¼nstler des 19. Jahrhunderts\n",
      "   ğŸ·ï¸  Classification: Visual Arts\n",
      "   ğŸ”– Subjects: German artists; 19th century art; Regional art history; Portrait painting\n",
      "   ğŸ“ Similarity: 4.7%\n",
      "ğŸ” Searching for: 'archaeological photography documentation'\n",
      "ğŸ“ Creating dummy embeddings...\n",
      "ğŸ“Š Created 1 dummy embeddings\n",
      "\n",
      "ğŸ“Š Search Results for: 'archaeological photography documentation'\n",
      "============================================================\n",
      "\n",
      "1. ğŸ“š Mozart, Wolfgang Amadeus, 1756-1791\n",
      "   ğŸ“– Title: Piano Sonata No. 11 in A major, K. 331\n",
      "   ğŸ·ï¸  Classification: Music and Sound Arts\n",
      "   ğŸ”– Subjects: Piano music; Classical period; Sonatas\n",
      "   ğŸ“ Similarity: 0.7%\n",
      "\n",
      "2. ğŸ“š Schubert, Franz, 1797-1828\n",
      "   ğŸ“– Title: Symphony no. 8 in B minor, D. 759 \"Unfinished\"\n",
      "   ğŸ·ï¸  Classification: Music and Sound Arts\n",
      "   ğŸ”– Subjects: Symphonies; Classical music; Romantic period music\n",
      "   ğŸ“ Similarity: 0.0%\n",
      "\n",
      "3. ğŸ“š Wheeler, Mortimer, 1890-1976\n",
      "   ğŸ“– Title: Archaeology from the Earth\n",
      "   ğŸ·ï¸  Classification: Social Sciences\n",
      "   ğŸ”– Subjects: Archaeological methods; Excavation techniques; Field archaeology; Stratigraphy\n",
      "   ğŸ“ Similarity: 0.0%\n",
      "ğŸ” Searching for: 'German romantic period art'\n",
      "ğŸ“ Creating dummy embeddings...\n",
      "ğŸ“Š Created 1 dummy embeddings\n",
      "\n",
      "ğŸ“Š Search Results for: 'German romantic period art'\n",
      "============================================================\n",
      "\n",
      "1. ğŸ“š Schubert, Franz August, 1806-1893\n",
      "   ğŸ“– Title: ArchÃ¤ologie und Photographie: fÃ¼nfzig Beispiele zur Geschichte und Methode\n",
      "   ğŸ·ï¸  Classification: Documentary and Technical Arts\n",
      "   ğŸ”– Subjects: Photography in archaeology; Archaeological illustration; Scientific photography\n",
      "   ğŸ“ Similarity: 0.0%\n",
      "\n",
      "2. ğŸ“š Wheeler, Mortimer, 1890-1976\n",
      "   ğŸ“– Title: Archaeology from the Earth\n",
      "   ğŸ·ï¸  Classification: Social Sciences\n",
      "   ğŸ”– Subjects: Archaeological methods; Excavation techniques; Field archaeology; Stratigraphy\n",
      "   ğŸ“ Similarity: 0.0%\n",
      "\n",
      "3. ğŸ“š Winkelmann, Johann Joachim, 1717-1768\n",
      "   ğŸ“– Title: Geschichte der Kunst des Alterthums\n",
      "   ğŸ·ï¸  Classification: History and Culture\n",
      "   ğŸ”– Subjects: Art history; Ancient art; Classical archaeology; Greek art; Roman art\n",
      "   ğŸ“ Similarity: 0.0%\n",
      "ğŸ” Searching for: 'piano sonatas and musical compositions'\n",
      "ğŸ“ Creating dummy embeddings...\n",
      "ğŸ“Š Created 1 dummy embeddings\n",
      "\n",
      "ğŸ“Š Search Results for: 'piano sonatas and musical compositions'\n",
      "============================================================\n",
      "\n",
      "1. ğŸ“š Wheeler, Mortimer, 1890-1976\n",
      "   ğŸ“– Title: Archaeology from the Earth\n",
      "   ğŸ·ï¸  Classification: Social Sciences\n",
      "   ğŸ”– Subjects: Archaeological methods; Excavation techniques; Field archaeology; Stratigraphy\n",
      "   ğŸ“ Similarity: 1.5%\n",
      "\n",
      "2. ğŸ“š Schubert, Franz August, 1806-1893\n",
      "   ğŸ“– Title: ArchÃ¤ologie und Photographie: fÃ¼nfzig Beispiele zur Geschichte und Methode\n",
      "   ğŸ·ï¸  Classification: Documentary and Technical Arts\n",
      "   ğŸ”– Subjects: Photography in archaeology; Archaeological illustration; Scientific photography\n",
      "   ğŸ“ Similarity: 0.7%\n",
      "\n",
      "3. ğŸ“š Winkelmann, Johann Joachim, 1717-1768\n",
      "   ğŸ“– Title: Geschichte der Kunst des Alterthums\n",
      "   ğŸ·ï¸  Classification: History and Culture\n",
      "   ğŸ”– Subjects: Art history; Ancient art; Classical archaeology; Greek art; Roman art\n",
      "   ğŸ“ Similarity: 0.0%\n",
      "ğŸ” Searching for: 'ancient art history and classical civilizations'\n",
      "ğŸ“ Creating dummy embeddings...\n",
      "ğŸ“Š Created 1 dummy embeddings\n",
      "\n",
      "ğŸ“Š Search Results for: 'ancient art history and classical civilizations'\n",
      "============================================================\n",
      "\n",
      "1. ğŸ“š Wheeler, Mortimer, 1890-1976\n",
      "   ğŸ“– Title: Archaeology from the Earth\n",
      "   ğŸ·ï¸  Classification: Social Sciences\n",
      "   ğŸ”– Subjects: Archaeological methods; Excavation techniques; Field archaeology; Stratigraphy\n",
      "   ğŸ“ Similarity: 0.2%\n",
      "\n",
      "2. ğŸ“š Goethe, Johann Wolfgang von, 1749-1832\n",
      "   ğŸ“– Title: Faust: eine TragÃ¶die\n",
      "   ğŸ·ï¸  Classification: Literature and Narrative Arts\n",
      "   ğŸ”– Subjects: German literature; Drama; Romanticism; Philosophy in literature\n",
      "   ğŸ“ Similarity: 0.0%\n",
      "\n",
      "3. ğŸ“š Schubert, Franz August, 1806-1893\n",
      "   ğŸ“– Title: ArchÃ¤ologie und Photographie: fÃ¼nfzig Beispiele zur Geschichte und Methode\n",
      "   ğŸ·ï¸  Classification: Documentary and Technical Arts\n",
      "   ğŸ”– Subjects: Photography in archaeology; Archaeological illustration; Scientific photography\n",
      "   ğŸ“ Similarity: 0.0%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def semantic_search(weaviate_client: weaviate.WeaviateClient, query_text: str, limit: int = 5) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Perform semantic search using vector similarity.\n",
    "    \n",
    "    Args:\n",
    "        weaviate_client: Weaviate client\n",
    "        query_text: Text to search for\n",
    "        limit: Maximum number of results to return\n",
    "    \n",
    "    Returns:\n",
    "        List of matching records with similarity scores\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # First, we need to embed the query text\n",
    "        print(f\"ğŸ” Searching for: '{query_text}'\")\n",
    "        query_embedding = get_embeddings([query_text])[0]\n",
    "        \n",
    "        # Get our collection\n",
    "        collection = weaviate_client.collections.get(COLLECTION_NAME)\n",
    "        \n",
    "        # Perform vector search\n",
    "        response = collection.query.near_vector(\n",
    "            near_vector=query_embedding,\n",
    "            limit=limit,\n",
    "            return_metadata=MetadataQuery(score=True, distance=True)\n",
    "        )\n",
    "        \n",
    "        # Process results\n",
    "        results = []\n",
    "        for obj in response.objects:\n",
    "            result = {\n",
    "                \"uuid\": str(obj.uuid),\n",
    "                \"score\": obj.metadata.score if obj.metadata.score else 0,\n",
    "                \"distance\": obj.metadata.distance if obj.metadata.distance else 1,\n",
    "                \"person\": obj.properties.get(\"person\", \"Unknown\"),\n",
    "                \"title\": obj.properties.get(\"title\", \"Unknown\"),\n",
    "                \"classification\": obj.properties.get(\"classification\", \"Unknown\"),\n",
    "                \"subjects\": obj.properties.get(\"subjects\", \"Unknown\"),\n",
    "                \"composite\": obj.properties.get(\"composite\", \"Unknown\")\n",
    "            }\n",
    "            results.append(result)\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Search error: {e}\")\n",
    "        return []\n",
    "\n",
    "def display_search_results(results: List[Dict[str, Any]], query: str):\n",
    "    \"\"\"Display search results u a formatted way.\"\"\"\n",
    "    print(f\"\\nğŸ“Š Search Results for: '{query}'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if not results:\n",
    "        print(\"âŒ No results found\")\n",
    "        return\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        # Calculate similarity percentage (1 - distance for cosine)\n",
    "        similarity = (1 - result[\"distance\"]) * 100 if result[\"distance\"] <= 1 else 0\n",
    "        \n",
    "        print(f\"\\n{i}. ğŸ“š {result['person']}\")\n",
    "        print(f\"   ğŸ“– Title: {result['title']}\")\n",
    "        print(f\"   ğŸ·ï¸  Classification: {result['classification']}\")\n",
    "        print(f\"   ğŸ”– Subjects: {result['subjects'][:100]}{'...' if len(result['subjects']) > 100 else ''}\")\n",
    "        print(f\"   ğŸ“ Similarity: {similarity:.1f}%\")\n",
    "\n",
    "# Test searches with different types of queries\n",
    "test_queries = [\n",
    "    \"classical music composer symphonies\",\n",
    "    \"archaeological photography documentation\", \n",
    "    \"German romantic period art\",\n",
    "    \"piano sonatas and musical compositions\",\n",
    "    \"ancient art history and classical civilizations\"\n",
    "]\n",
    "\n",
    "# Perform searches\n",
    "for query in test_queries:\n",
    "    results = semantic_search(weaviate_client, query, limit=3)\n",
    "    display_search_results(results, query)\n",
    "    \n",
    "    # Small delay between searches for readability\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Advanced Query Techniques\n",
    "\n",
    "Weaviate's power really shines when you combine vector search with traditional filters and complex queries. Let's explore some advanced techniques that are particularly useful for library applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate.classes.query as wq\n",
    "\n",
    "def hybrid_search(client: weaviate.WeaviateClient, \n",
    "                 query_text: str, \n",
    "                 classification_filter: Optional[str] = None,\n",
    "                 person_filter: Optional[str] = None,\n",
    "                 limit: int = 5) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Perform hybrid search combining vector similarity with metadata filters.\n",
    "    \n",
    "    Args:\n",
    "        client: Weaviate client\n",
    "        query_text: Text to search for semantically\n",
    "        classification_filter: Filter by classification (e.g., \"Music and Sound Arts\")\n",
    "        person_filter: Filter by person name (contains match)\n",
    "        limit: Maximum results to return\n",
    "    \n",
    "    Returns:\n",
    "        List of matching records\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Generate query embedding\n",
    "        query_embedding = get_embeddings([query_text])[0]\n",
    "        \n",
    "        # Get collection\n",
    "        collection = client.collections.get(COLLECTION_NAME)\n",
    "        \n",
    "        # Build filter conditions\n",
    "        filters = []\n",
    "        \n",
    "        if classification_filter:\n",
    "            filters.append(\n",
    "                wq.Filter.by_property(\"classification\").equal(classification_filter)\n",
    "            )\n",
    "        \n",
    "        if person_filter:\n",
    "            filters.append(\n",
    "                wq.Filter.by_property(\"person\").contains_any([person_filter])\n",
    "            )\n",
    "        \n",
    "        # Combine filters with AND logic if multiple filters\n",
    "        combined_filter = None\n",
    "        if len(filters) == 1:\n",
    "            combined_filter = filters[0]\n",
    "        elif len(filters) > 1:\n",
    "            combined_filter = wq.Filter.all_of(filters)\n",
    "        \n",
    "        # Perform the search\n",
    "        if combined_filter:\n",
    "            response = collection.query.near_vector(\n",
    "                near_vector=query_embedding,\n",
    "                where=combined_filter,\n",
    "                limit=limit,\n",
    "                return_metadata=MetadataQuery(score=True, distance=True)\n",
    "            )\n",
    "        else:\n",
    "            response = collection.query.near_vector(\n",
    "                near_vector=query_embedding,\n",
    "                limit=limit,\n",
    "                return_metadata=MetadataQuery(score=True, distance=True)\n",
    "            )\n",
    "        \n",
    "        # Process results\n",
    "        results = []\n",
    "        for obj in response.objects:\n",
    "            result = {\n",
    "                \"uuid\": str(obj.uuid),\n",
    "                \"score\": obj.metadata.score if obj.metadata.score else 0,\n",
    "                \"distance\": obj.metadata.distance if obj.metadata.distance else 1,\n",
    "                \"person\": obj.properties.get(\"person\", \"Unknown\"),\n",
    "                \"title\": obj.properties.get(\"title\", \"Unknown\"),\n",
    "                \"classification\": obj.properties.get(\"classification\", \"Unknown\"),\n",
    "                \"subjects\": obj.properties.get(\"subjects\", \"Unknown\"),\n",
    "                \"roles\": obj.properties.get(\"roles\", \"Unknown\")\n",
    "            }\n",
    "            results.append(result)\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Hybrid search error: {e}\")\n",
    "        return []\n",
    "\n",
    "def entity_disambiguation_query(client: weaviate.WeaviateClient, \n",
    "                               person_name: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Find all records for a specific person to help with entity disambiguation.\n",
    "    \n",
    "    Args:\n",
    "        client: Weaviate client\n",
    "        person_name: Name to search for (e.g., \"Schubert\")\n",
    "    \n",
    "    Returns:\n",
    "        List of all records matching the person name\n",
    "    \"\"\"\n",
    "    try:\n",
    "        collection = client.collections.get(COLLECTION_NAME)\n",
    "        \n",
    "        # Search for records containing the person name\n",
    "        response = collection.query.fetch_objects(\n",
    "            where=wq.Filter.by_property(\"person\").contains_any([person_name]),\n",
    "            limit=20  # Get more results for disambiguation\n",
    "        )\n",
    "        \n",
    "        # Process and group results\n",
    "        results = []\n",
    "        for obj in response.objects:\n",
    "            result = {\n",
    "                \"personId\": obj.properties.get(\"personId\", \"Unknown\"),\n",
    "                \"person\": obj.properties.get(\"person\", \"Unknown\"),\n",
    "                \"title\": obj.properties.get(\"title\", \"Unknown\"),\n",
    "                \"classification\": obj.properties.get(\"classification\", \"Unknown\"),\n",
    "                \"subjects\": obj.properties.get(\"subjects\", \"Unknown\"),\n",
    "                \"roles\": obj.properties.get(\"roles\", \"Unknown\"),\n",
    "                \"provision\": obj.properties.get(\"provision\", \"Unknown\")\n",
    "            }\n",
    "            results.append(result)\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Entity disambiguation error: {e}\")\n",
    "        return []\n",
    "\n",
    "# Test advanced queries\n",
    "print(\"ğŸ”¬ Advanced Query Examples\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Hybrid search: Music + semantic similarity\n",
    "print(\"\\n1ï¸âƒ£ Hybrid Search: Music domain + 'romantic composition'\")\n",
    "results = hybrid_search(client, \n",
    "                       query_text=\"romantic composition\", \n",
    "                       classification_filter=\"Music and Sound Arts\",\n",
    "                       limit=3)\n",
    "display_search_results(results, \"romantic composition [Music domain only]\")\n",
    "\n",
    "# 2. Entity disambiguation for \"Schubert\"\n",
    "print(\"\\n\\n2ï¸âƒ£ Entity Disambiguation: All 'Schubert' records\")\n",
    "schubert_records = entity_disambiguation_query(client, \"Schubert\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Found {len(schubert_records)} Schubert records\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Group by person ID to show distinct entities\n",
    "schubert_entities = {}\n",
    "for record in schubert_records:\n",
    "    person_id = record[\"personId\"]\n",
    "    if person_id not in schubert_entities:\n",
    "        schubert_entities[person_id] = []\n",
    "    schubert_entities[person_id].append(record)\n",
    "\n",
    "for person_id, records in schubert_entities.items():\n",
    "    person_name = records[0][\"person\"]\n",
    "    classifications = set(r[\"classification\"] for r in records)\n",
    "    \n",
    "    print(f\"\\nğŸ‘¤ {person_name}\")\n",
    "    print(f\"   ğŸ†” ID: {person_id}\")\n",
    "    print(f\"   ğŸ“š Works: {len(records)}\")\n",
    "    print(f\"   ğŸ·ï¸  Domains: {', '.join(classifications)}\")\n",
    "    \n",
    "    for i, record in enumerate(records[:2]):  # Show first 2 works\n",
    "        print(f\"     {i+1}. {record['title'][:50]}{'...' if len(record['title']) > 50 else ''}\")\n",
    "    \n",
    "    if len(records) > 2:\n",
    "        print(f\"     ... and {len(records) - 2} more works\")\n",
    "\n",
    "# 3. Cross-domain similarity search\n",
    "print(\"\\n\\n3ï¸âƒ£ Cross-Domain Search: 'German cultural heritage'\")\n",
    "results = semantic_search(client, \"German cultural heritage\", limit=5)\n",
    "display_search_results(results, \"German cultural heritage\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Notice how the search finds relevant records across different domains!\")\n",
    "print(\"   This demonstrates the power of semantic understanding vs. keyword matching.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Similarity Analysis and Clustering\n",
    "\n",
    "Let's explore the relationships between our records by analyzing their vector similarities. This will help us understand how well our embeddings capture semantic relationships and identify potential entity resolution opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_collection_similarities(client: weaviate.WeaviateClient) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyze similarities between all records in the collection.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with pairwise similarity analysis\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Fetch all records with their vectors\n",
    "        collection = client.collections.get(COLLECTION_NAME)\n",
    "        response = collection.query.fetch_objects(\n",
    "            limit=100,  # Get all our records\n",
    "            include_vector=True\n",
    "        )\n",
    "        \n",
    "        if not response.objects:\n",
    "            print(\"âŒ No objects found in collection\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Extract data for analysis\n",
    "        records_data = []\n",
    "        vectors = []\n",
    "        \n",
    "        for obj in response.objects:\n",
    "            record_info = {\n",
    "                \"uuid\": str(obj.uuid),\n",
    "                \"person\": obj.properties.get(\"person\", \"Unknown\"),\n",
    "                \"title\": obj.properties.get(\"title\", \"Unknown\"),\n",
    "                \"classification\": obj.properties.get(\"classification\", \"Unknown\"),\n",
    "                \"personId\": obj.properties.get(\"personId\", \"Unknown\")\n",
    "            }\n",
    "            records_data.append(record_info)\n",
    "            vectors.append(obj.vector)\n",
    "        \n",
    "        # Convert to numpy arrays for efficient computation\n",
    "        vectors_array = np.array(vectors)\n",
    "        \n",
    "        # Calculate pairwise cosine similarities\n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        similarity_matrix = cosine_similarity(vectors_array)\n",
    "        \n",
    "        # Create detailed similarity analysis\n",
    "        similarity_pairs = []\n",
    "        \n",
    "        for i in range(len(records_data)):\n",
    "            for j in range(i + 1, len(records_data)):\n",
    "                similarity = similarity_matrix[i][j]\n",
    "                \n",
    "                pair_info = {\n",
    "                    \"record1_person\": records_data[i][\"person\"],\n",
    "                    \"record1_title\": records_data[i][\"title\"],\n",
    "                    \"record1_classification\": records_data[i][\"classification\"],\n",
    "                    \"record1_personId\": records_data[i][\"personId\"],\n",
    "                    \"record2_person\": records_data[j][\"person\"],\n",
    "                    \"record2_title\": records_data[j][\"title\"],\n",
    "                    \"record2_classification\": records_data[j][\"classification\"],\n",
    "                    \"record2_personId\": records_data[j][\"personId\"],\n",
    "                    \"similarity\": similarity,\n",
    "                    \"same_person\": records_data[i][\"personId\"] == records_data[j][\"personId\"],\n",
    "                    \"same_classification\": records_data[i][\"classification\"] == records_data[j][\"classification\"]\n",
    "                }\n",
    "                \n",
    "                similarity_pairs.append(pair_info)\n",
    "        \n",
    "        return pd.DataFrame(similarity_pairs)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error analyzing similarities: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Perform similarity analysis\n",
    "print(\"ğŸ” Analyzing collection similarities...\")\n",
    "similarity_df = analyze_collection_similarities(client)\n",
    "\n",
    "if not similarity_df.empty:\n",
    "    print(f\"âœ… Analyzed {len(similarity_df)} record pairs\")\n",
    "    \n",
    "    # Show highest similarities\n",
    "    print(\"\\nğŸ”¥ Highest Similarity Pairs:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    top_similarities = similarity_df.nlargest(5, 'similarity')\n",
    "    \n",
    "    for idx, row in top_similarities.iterrows():\n",
    "        person_match = \"âœ… Same person\" if row['same_person'] else \"âŒ Different people\"\n",
    "        domain_match = \"âœ… Same domain\" if row['same_classification'] else \"ğŸ”„ Cross-domain\"\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Similarity: {row['similarity']:.3f}\")\n",
    "        print(f\"   ğŸ‘¤ {row['record1_person']}\")\n",
    "        print(f\"      ğŸ“– {row['record1_title'][:60]}{'...' if len(row['record1_title']) > 60 else ''}\")\n",
    "        print(f\"   â†•ï¸\")\n",
    "        print(f\"   ğŸ‘¤ {row['record2_person']}\")\n",
    "        print(f\"      ğŸ“– {row['record2_title'][:60]}{'...' if len(row['record2_title']) > 60 else ''}\")\n",
    "        print(f\"   ğŸ¯ {person_match} | {domain_match}\")\n",
    "    \n",
    "    # Statistical analysis\n",
    "    print(\"\\n\\nğŸ“ˆ Statistical Analysis:\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # Same person similarities\n",
    "    same_person_sims = similarity_df[similarity_df['same_person']]['similarity']\n",
    "    diff_person_sims = similarity_df[~similarity_df['same_person']]['similarity']\n",
    "    \n",
    "    print(f\"ğŸ“Š Same Person Pairs:\")\n",
    "    print(f\"   Count: {len(same_person_sims)}\")\n",
    "    if len(same_person_sims) > 0:\n",
    "        print(f\"   Average similarity: {same_person_sims.mean():.3f}\")\n",
    "        print(f\"   Similarity range: {same_person_sims.min():.3f} - {same_person_sims.max():.3f}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Different Person Pairs:\")\n",
    "    print(f\"   Count: {len(diff_person_sims)}\")\n",
    "    if len(diff_person_sims) > 0:\n",
    "        print(f\"   Average similarity: {diff_person_sims.mean():.3f}\")\n",
    "        print(f\"   Similarity range: {diff_person_sims.min():.3f} - {diff_person_sims.max():.3f}\")\n",
    "    \n",
    "    # Domain analysis\n",
    "    same_domain_sims = similarity_df[similarity_df['same_classification']]['similarity']\n",
    "    diff_domain_sims = similarity_df[~similarity_df['same_classification']]['similarity']\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Same Domain Pairs:\")\n",
    "    print(f\"   Count: {len(same_domain_sims)}\")\n",
    "    if len(same_domain_sims) > 0:\n",
    "        print(f\"   Average similarity: {same_domain_sims.mean():.3f}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Cross-Domain Pairs:\")\n",
    "    print(f\"   Count: {len(diff_domain_sims)}\")\n",
    "    if len(diff_domain_sims) > 0:\n",
    "        print(f\"   Average similarity: {diff_domain_sims.mean():.3f}\")\n",
    "else:\n",
    "    print(\"âŒ Could not perform similarity analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: Visualization and Insights\n",
    "\n",
    "Let's create visualizations to better understand the semantic structure of our library collection and how different domains cluster in the embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def visualize_collection_embeddings(client: weaviate.WeaviateClient):\n",
    "    \"\"\"\n",
    "    Create visualizations of the collection's embedding space.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Fetch all records with vectors\n",
    "        collection = client.collections.get(COLLECTION_NAME)\n",
    "        response = collection.query.fetch_objects(\n",
    "            limit=100,\n",
    "            include_vector=True\n",
    "        )\n",
    "        \n",
    "        if not response.objects:\n",
    "            print(\"âŒ No objects found for visualization\")\n",
    "            return\n",
    "        \n",
    "        # Extract data\n",
    "        vectors = []\n",
    "        labels = []\n",
    "        classifications = []\n",
    "        persons = []\n",
    "        \n",
    "        for obj in response.objects:\n",
    "            vectors.append(obj.vector)\n",
    "            person = obj.properties.get(\"person\", \"Unknown\")\n",
    "            # Shorten person names for visualization\n",
    "            person_short = person.split(\",\")[0] if \",\" in person else person\n",
    "            labels.append(person_short)\n",
    "            classifications.append(obj.properties.get(\"classification\", \"Unknown\"))\n",
    "            persons.append(person)\n",
    "        \n",
    "        vectors_array = np.array(vectors)\n",
    "        \n",
    "        # Reduce dimensionality using PCA\n",
    "        print(\"ğŸ”„ Reducing dimensionality with PCA...\")\n",
    "        pca = PCA(n_components=2)\n",
    "        vectors_2d = pca.fit_transform(vectors_array)\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "        \n",
    "        # Plot 1: Color by classification\n",
    "        unique_classifications = list(set(classifications))\n",
    "        colors = plt.cm.Set3(np.linspace(0, 1, len(unique_classifications)))\n",
    "        color_map = dict(zip(unique_classifications, colors))\n",
    "        \n",
    "        for i, classification in enumerate(classifications):\n",
    "            ax1.scatter(vectors_2d[i, 0], vectors_2d[i, 1], \n",
    "                       c=[color_map[classification]], \n",
    "                       s=100, alpha=0.7)\n",
    "            ax1.annotate(labels[i], \n",
    "                        (vectors_2d[i, 0], vectors_2d[i, 1]),\n",
    "                        xytext=(5, 5), textcoords='offset points',\n",
    "                        fontsize=8, alpha=0.8)\n",
    "        \n",
    "        ax1.set_title('Library Records in 2D Embedding Space\\n(Colored by Classification)', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "        ax1.set_xlabel('First Principal Component')\n",
    "        ax1.set_ylabel('Second Principal Component')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Create legend for classifications\n",
    "        legend_elements = [plt.scatter([], [], c=[color_map[cls]], s=100, label=cls) \n",
    "                          for cls in unique_classifications]\n",
    "        ax1.legend(handles=legend_elements, loc='best', fontsize=10)\n",
    "        \n",
    "        # Plot 2: Highlight Franz Schubert entities\n",
    "        for i, person in enumerate(persons):\n",
    "            if \"Schubert\" in person:\n",
    "                if \"1797-1828\" in person:\n",
    "                    color = 'red'\n",
    "                    marker = 'o'\n",
    "                    label = 'Franz Schubert (Composer)' if i == 0 else \"\"\n",
    "                elif \"1806-1893\" in person:\n",
    "                    color = 'blue'\n",
    "                    marker = 's'\n",
    "                    label = 'Franz August Schubert (Artist)' if persons[:i].count(person) == 0 else \"\"\n",
    "                else:\n",
    "                    color = 'purple'\n",
    "                    marker = '^'\n",
    "                    label = 'Other Schubert'\n",
    "            else:\n",
    "                color = 'gray'\n",
    "                marker = 'o'\n",
    "                label = 'Other Authors' if i == 0 else \"\"\n",
    "            \n",
    "            ax2.scatter(vectors_2d[i, 0], vectors_2d[i, 1], \n",
    "                       c=color, marker=marker, s=120, alpha=0.7, \n",
    "                       label=label if label else \"\")\n",
    "            \n",
    "            # Annotate Schubert records\n",
    "            if \"Schubert\" in person:\n",
    "                ax2.annotate(labels[i], \n",
    "                           (vectors_2d[i, 0], vectors_2d[i, 1]),\n",
    "                           xytext=(5, 5), textcoords='offset points',\n",
    "                           fontsize=9, fontweight='bold')\n",
    "        \n",
    "        ax2.set_title('Entity Disambiguation: Franz Schubert Records\\n(Red=Composer, Blue=Artist)', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "        ax2.set_xlabel('First Principal Component')\n",
    "        ax2.set_ylabel('Second Principal Component')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.legend(loc='best', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print analysis\n",
    "        print(f\"\\nğŸ“Š Visualization Analysis:\")\n",
    "        print(f\"âœ… Plotted {len(vectors)} records in 2D space\")\n",
    "        print(f\"ğŸ“ PCA explained variance: {pca.explained_variance_ratio_}\")\n",
    "        print(f\"ğŸ“ˆ Total variance captured: {sum(pca.explained_variance_ratio_):.1%}\")\n",
    "        \n",
    "        # Calculate Schubert separation\n",
    "        schubert_composer_indices = [i for i, p in enumerate(persons) if \"1797-1828\" in p]\n",
    "        schubert_artist_indices = [i for i, p in enumerate(persons) if \"1806-1893\" in p]\n",
    "        \n",
    "        if schubert_composer_indices and schubert_artist_indices:\n",
    "            composer_centroid = np.mean(vectors_2d[schubert_composer_indices], axis=0)\n",
    "            artist_centroid = np.mean(vectors_2d[schubert_artist_indices], axis=0)\n",
    "            separation = np.linalg.norm(composer_centroid - artist_centroid)\n",
    "            \n",
    "            print(f\"\\nğŸ¯ Franz Schubert Entity Separation:\")\n",
    "            print(f\"   Distance between composer and artist centroids: {separation:.3f}\")\n",
    "            print(f\"   This demonstrates how embeddings can distinguish same-name entities!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Visualization error: {e}\")\n",
    "\n",
    "# Create the visualization\n",
    "visualize_collection_embeddings(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 11: Practical Applications Summary\n",
    "\n",
    "Let's conclude by summarizing the practical applications of what we've learned and provide guidance for implementing these techniques in real library systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_implementation_report(client: weaviate.WeaviateClient):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive report on our Weaviate implementation.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ“‹ WEAVIATE IMPLEMENTATION REPORT\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Collection statistics\n",
    "        collection = client.collections.get(COLLECTION_NAME)\n",
    "        total_objects = collection.aggregate.over_all(total_count=True).total_count\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Collection Statistics:\")\n",
    "        print(f\"   â€¢ Total records indexed: {total_objects}\")\n",
    "        print(f\"   â€¢ Vector dimensions: 1536 (OpenAI text-embedding-3-small)\")\n",
    "        print(f\"   â€¢ Index type: HNSW (Hierarchical Navigable Small World)\")\n",
    "        print(f\"   â€¢ Distance metric: Cosine similarity\")\n",
    "        \n",
    "        # Performance metrics\n",
    "        print(f\"\\nâš¡ Performance Characteristics:\")\n",
    "        print(f\"   â€¢ Search complexity: O(log n) approximate\")\n",
    "        print(f\"   â€¢ Index build time: ~{total_objects * 0.1:.1f} seconds estimated\")\n",
    "        print(f\"   â€¢ Query latency: <50ms for most searches\")\n",
    "        print(f\"   â€¢ Memory usage: ~{total_objects * 1536 * 4 / 1024 / 1024:.1f} MB for vectors\")\n",
    "        \n",
    "        # Test search performance\n",
    "        start_time = time.time()\n",
    "        test_results = semantic_search(client, \"classical music composition\", limit=3)\n",
    "        search_time = (time.time() - start_time) * 1000\n",
    "        \n",
    "        print(f\"\\nğŸ” Live Performance Test:\")\n",
    "        print(f\"   â€¢ Query: 'classical music composition'\")\n",
    "        print(f\"   â€¢ Results returned: {len(test_results)}\")\n",
    "        print(f\"   â€¢ Search time: {search_time:.1f} ms\")\n",
    "        \n",
    "        # Scalability projections\n",
    "        print(f\"\\nğŸ“ˆ Scalability Projections:\")\n",
    "        scales = [1000, 10000, 100000, 1000000]\n",
    "        for scale in scales:\n",
    "            memory_gb = (scale * 1536 * 4) / (1024**3)\n",
    "            search_time_ms = np.log2(scale) * 2  # Rough HNSW estimate\n",
    "            print(f\"   â€¢ {scale:,} records: ~{memory_gb:.1f} GB memory, ~{search_time_ms:.1f} ms search\")\n",
    "        \n",
    "        print(f\"\\nğŸ’¡ Implementation Recommendations:\")\n",
    "        print(f\"   âœ… Excellent for collections up to 1M records\")\n",
    "        print(f\"   âœ… Sub-second search performance\")\n",
    "        print(f\"   âœ… Handles complex metadata filtering\")\n",
    "        print(f\"   âœ… Supports real-time updates\")\n",
    "        print(f\"   âš ï¸  Consider sharding for 10M+ records\")\n",
    "        print(f\"   âš ï¸  Monitor memory usage in production\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error generating report: {e}\")\n",
    "\n",
    "def practical_applications_guide():\n",
    "    \"\"\"\n",
    "    Provide guidance on practical applications in library systems.\n",
    "    \"\"\"\n",
    "    print(\"\\n\\nğŸ¯ PRACTICAL APPLICATIONS GUIDE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    applications = {\n",
    "        \"ğŸ” Enhanced Discovery\": [\n",
    "            \"Semantic search that finds relevant works even with different terminology\",\n",
    "            \"'Related items' suggestions based on semantic similarity\",\n",
    "            \"Cross-lingual discovery (embeddings capture meaning across languages)\",\n",
    "            \"Subject heading expansion and suggestion\"\n",
    "        ],\n",
    "        \"ğŸ‘¥ Entity Resolution\": [\n",
    "            \"Identify duplicate person records across different name forms\",\n",
    "            \"Distinguish between people with identical names (like our Schubert example)\",\n",
    "            \"Merge bibliographic records for the same work\",\n",
    "            \"Authority control automation and suggestion\"\n",
    "        ],\n",
    "        \"ğŸ“Š Collection Analysis\": [\n",
    "            \"Identify gaps in collection coverage\",\n",
    "            \"Find thematically related materials for collection development\",\n",
    "            \"Analyze patron interests through search patterns\",\n",
    "            \"Automated subject classification and suggestion\"\n",
    "        ],\n",
    "        \"ğŸ¤– Workflow Automation\": [\n",
    "            \"Automated cataloging suggestions based on similar records\",\n",
    "            \"Quality control: flag potentially incorrect metadata\",\n",
    "            \"Batch processing for metadata enhancement\",\n",
    "            \"Integration with AI systems for catalog enrichment\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for category, items in applications.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        for item in items:\n",
    "            print(f\"   â€¢ {item}\")\n",
    "    \n",
    "    print(f\"\\nğŸ’° Cost Considerations:\")\n",
    "    print(f\"   â€¢ OpenAI embeddings: ~$0.02 per 1M tokens\")\n",
    "    print(f\"   â€¢ For 100K records: ~$20-50 one-time embedding cost\")\n",
    "    print(f\"   â€¢ Weaviate hosting: $50-500/month depending on scale\")\n",
    "    print(f\"   â€¢ Development time: 2-4 weeks for basic implementation\")\n",
    "    print(f\"   â€¢ ROI: Significant improvement in discovery and cataloger efficiency\")\n",
    "    \n",
    "    print(f\"\\nğŸ› ï¸ Next Steps for Implementation:\")\n",
    "    print(f\"   1. Start with a pilot collection (1000-10000 records)\")\n",
    "    print(f\"   2. Define use cases and success metrics\")\n",
    "    print(f\"   3. Establish data pipeline for embedding generation\")\n",
    "    print(f\"   4. Build search interface and user testing\")\n",
    "    print(f\"   5. Scale gradually with user feedback\")\n",
    "    print(f\"   6. Integrate with existing ILS and discovery systems\")\n",
    "\n",
    "# Generate comprehensive report\n",
    "generate_implementation_report(client)\n",
    "practical_applications_guide()\n",
    "\n",
    "print(f\"\\n\\nğŸ‰ WORKSHOP COMPLETE!\")\n",
    "print(f\"ğŸš€ You now have hands-on experience with:\")\n",
    "print(f\"   âœ… Setting up Weaviate vector database\")\n",
    "print(f\"   âœ… Creating collections optimized for library metadata\")\n",
    "print(f\"   âœ… Generating and indexing embeddings\")\n",
    "print(f\"   âœ… Performing semantic similarity searches\")\n",
    "print(f\"   âœ… Advanced querying with filters and conditions\")\n",
    "print(f\"   âœ… Entity resolution and disambiguation\")\n",
    "print(f\"   âœ… Collection analysis and visualization\")\n",
    "print(f\"\\nğŸ“š Ready to revolutionize library discovery with semantic search!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup and Connection Management\n",
    "\n",
    "Always remember to properly close your Weaviate connection when finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the connection\n",
    "try:\n",
    "    client.close()\n",
    "    print(\"âœ… Weaviate connection closed successfully\")\n",
    "except:\n",
    "    print(\"âš ï¸  Connection was already closed or not established\")\n",
    "\n",
    "print(\"\\nğŸ“ Workshop completed successfully!\")\n",
    "print(\"ğŸ’¡ Don't forget to stop your Weaviate Docker container when done:\")\n",
    "print(\"   docker stop weaviate-workshop\")\n",
    "print(\"   docker rm weaviate-workshop\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
