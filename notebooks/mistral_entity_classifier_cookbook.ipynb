{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mistral Entity Taxonomy Classifier\n",
    "\n",
    "Step-by-step implementation following the Mistral Classifier Factory cookbook.\n",
    "This notebook trains a multi-label classifier for entity taxonomy classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install mistralai pandas matplotlib seaborn wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T19:47:00.994040Z",
     "iopub.status.busy": "2025-06-23T19:47:00.993476Z",
     "iopub.status.idle": "2025-06-23T19:47:01.007647Z",
     "shell.execute_reply": "2025-06-23T19:47:01.007220Z",
     "shell.execute_reply.started": "2025-06-23T19:47:00.994004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mistral API key found\n",
      "‚úÖ Weights & Biases API key found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "from mistralai import Mistral\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = Path(\"../data\")\n",
    "OUTPUT_DIR = Path(\"../data/output\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set your API keys here\n",
    "MISTRAL_API_KEY = os.environ.get(\"MISTRAL_API_KEY\")\n",
    "WANDB_API_KEY = os.environ.get(\"WANDB_API_KEY\")\n",
    "\n",
    "if not MISTRAL_API_KEY:\n",
    "    print(\"‚ö†Ô∏è Please set MISTRAL_API_KEY:\")\n",
    "    print(\"os.environ['MISTRAL_API_KEY'] = 'your_key_here'\")\n",
    "else:\n",
    "    print(\"‚úÖ Mistral API key found\")\n",
    "\n",
    "if not WANDB_API_KEY:\n",
    "    print(\"‚ö†Ô∏è Please set WANDB_API_KEY for experiment tracking:\")\n",
    "    print(\"os.environ['WANDB_API_KEY'] = 'your_key_here'\")\n",
    "else:\n",
    "    print(\"‚úÖ Weights & Biases API key found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T19:47:06.374973Z",
     "iopub.status.busy": "2025-06-23T19:47:06.374281Z",
     "iopub.status.idle": "2025-06-23T19:47:06.405160Z",
     "shell.execute_reply": "2025-06-23T19:47:06.404833Z",
     "shell.execute_reply.started": "2025-06-23T19:47:06.374942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Mistral client initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize Mistral client\n",
    "client = Mistral(api_key=MISTRAL_API_KEY)\n",
    "print(\"ü§ñ Mistral client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load entity data\n",
    "entity_df = pd.read_csv(DATA_DIR / \"input\" / \"training_dataset.csv\")\n",
    "print(f\"Loaded {len(entity_df)} entities\")\n",
    "\n",
    "# Load parallel classifications\n",
    "with open(DATA_DIR / \"input\" / \"parallel_classifications.json\", 'r', encoding='utf-8') as f:\n",
    "    classifications = json.load(f)\n",
    "print(f\"Loaded {len(classifications)} classifications\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nüìä Sample entity:\")\n",
    "print(entity_df[['personId', 'person', 'composite']].head(1))\n",
    "\n",
    "print(\"\\nüìä Sample classification:\")\n",
    "sample_key = list(classifications.keys())[0]\n",
    "sample = classifications[sample_key]\n",
    "print(f\"PersonID: {sample_key}\")\n",
    "print(f\"Labels: {sample['label']}\")\n",
    "print(f\"Paths: {sample['path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create entity lookup\n",
    "entity_lookup = {}\n",
    "for _, row in entity_df.iterrows():\n",
    "    person_id = str(row['personId'])\n",
    "    entity_lookup[person_id] = row['composite']\n",
    "\n",
    "print(f\"Created entity lookup for {len(entity_lookup)} entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Mistral format\n",
    "training_examples = []\n",
    "\n",
    "for person_id, classification_data in classifications.items():\n",
    "    # Get composite text\n",
    "    composite_text = entity_lookup.get(person_id)\n",
    "    if not composite_text:\n",
    "        continue\n",
    "    \n",
    "    # Extract labels and parent categories\n",
    "    labels_list = classification_data.get('label', [])\n",
    "    paths_list = classification_data.get('path', [])\n",
    "    \n",
    "    if not labels_list:\n",
    "        continue\n",
    "    \n",
    "    # Extract parent categories from paths\n",
    "    parent_categories = []\n",
    "    for path in paths_list:\n",
    "        if \" > \" in path:\n",
    "            parent_categories.append(path.split(\" > \")[0])\n",
    "    \n",
    "    # Create training example in Mistral format\n",
    "    training_examples.append({\n",
    "        \"text\": composite_text,\n",
    "        \"labels\": {\n",
    "            \"domain\": labels_list,  # Multi-label list\n",
    "            \"parent_category\": parent_categories\n",
    "        }\n",
    "    })\n",
    "\n",
    "print(f\"Created {len(training_examples)} training examples\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nüìù Sample training example:\")\n",
    "sample_ex = training_examples[0]\n",
    "print(f\"Text: {sample_ex['text'][:100]}...\")\n",
    "print(f\"Domains: {sample_ex['labels']['domain']}\")\n",
    "print(f\"Parents: {sample_ex['labels']['parent_category']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data (80% train, 20% validation)\n",
    "random.seed(42)\n",
    "random.shuffle(training_examples)\n",
    "\n",
    "split_idx = int(len(training_examples) * 0.8)\n",
    "train_examples = training_examples[:split_idx]\n",
    "val_examples = training_examples[split_idx:]\n",
    "\n",
    "print(f\"Training set: {len(train_examples)} examples\")\n",
    "print(f\"Validation set: {len(val_examples)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to JSONL files\n",
    "def save_jsonl(examples, filepath):\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        for example in examples:\n",
    "            f.write(json.dumps(example, ensure_ascii=False) + '\\n')\n",
    "    print(f\"Saved {len(examples)} examples to {filepath}\")\n",
    "\n",
    "train_path = OUTPUT_DIR / \"mistral_train.jsonl\"\n",
    "val_path = OUTPUT_DIR / \"mistral_val.jsonl\"\n",
    "\n",
    "save_jsonl(train_examples, train_path)\n",
    "save_jsonl(val_examples, val_path)\n",
    "\n",
    "print(\"‚úÖ Data preparation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Upload Training Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the training data\n",
    "print(\"üì§ Uploading training data...\")\n",
    "training_data = client.files.upload(\n",
    "    file={\n",
    "        \"file_name\": \"mistral_train.jsonl\",\n",
    "        \"content\": open(train_path, \"rb\"),\n",
    "    }\n",
    ")\n",
    "print(f\"‚úÖ Training file uploaded: {training_data.id}\")\n",
    "\n",
    "# Upload the validation data\n",
    "print(\"üì§ Uploading validation data...\")\n",
    "validation_data = client.files.upload(\n",
    "    file={\n",
    "        \"file_name\": \"mistral_val.jsonl\",\n",
    "        \"content\": open(val_path, \"rb\"),\n",
    "    }\n",
    ")\n",
    "print(f\"‚úÖ Validation file uploaded: {validation_data.id}\")\n",
    "\n",
    "print(\"\\nüìã File IDs:\")\n",
    "print(f\"Training: {training_data.id}\")\n",
    "print(f\"Validation: {validation_data.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Fine-tuning Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fine-tuning job with W&B integration\n",
    "print(\"üöÄ Creating fine-tuning job...\")\n",
    "\n",
    "# job_config = {\n",
    "#     \"model\": \"ministral-3b-latest\",\n",
    "#     \"job_type\": \"classifier\",\n",
    "#     \"training_files\": [{\"file_id\": training_id, \"weight\": 1}],\n",
    "#     \"validation_files\": [validation_id],\n",
    "#     \"hyperparameters\": {\n",
    "#         \"training_steps\": 250,\n",
    "#         \"learning_rate\": 0.00007\n",
    "#     },\n",
    "#     \"auto_start\": True,  # Start manually\n",
    "#     integrations=[\n",
    "#     {\n",
    "#         \"project\": \"entity_resolver\",\n",
    "        \n",
    "#         \"api_key\": \"WANDB_API_KEY\",\n",
    "#     }\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "# # Add W&B integration if available\n",
    "# if WANDB_API_KEY:\n",
    "    \n",
    "#     job_config[\"integrations\"] = {\n",
    "#         \"wandb\": {\n",
    "#             \"project\": \"entity_resolver\",\n",
    "#             \"name\": wandb_run_name,\n",
    "#             \"tags\": [\"mistral\", \"entity-resolution\", \"multilabel\", \"taxonomy\"]\n",
    "#         }\n",
    "#     }\n",
    "#     print(f\"üìä W&B integration enabled: {wandb_run_name}\")\n",
    "\n",
    "created_jobs = client.fine_tuning.jobs.create(\n",
    "    model=\"ministral-3b-latest\",\n",
    "    job_type=\"classifier\",\n",
    "    training_files=[{\"file_id\": training_id, \"weight\": 1}],\n",
    "    validation_files=[validation_id],\n",
    "    hyperparameters={\n",
    "        \"training_steps\": 250,\n",
    "        \"learning_rate\":0.00007\n",
    "    },\n",
    "    auto_start=True,\n",
    "    integrations=[\n",
    "        {\n",
    "            \"project\": \"entity_resolver\",\n",
    "            \"name\": f\"mistral-entity-classifier-{int(time.time())}\",  \n",
    "            \"api_key\": WANDB_API_KEY,\n",
    "            \"tags\": [\"mistral\", \"entity-resolution\", \"multilabel\", \"taxonomy\"]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "#created_job = client.fine_tuning.jobs.create(**job_config)\n",
    "\n",
    "print(\"‚úÖ Fine-tuning job created!\")\n",
    "print(json.dumps(created_job.model_dump(), indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = created_jobs.id\n",
    "print(f\"‚úÖ Training job created: {job_id}\")\n",
    "    \n",
    "print(json.dumps(created_jobs.model_dump(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Start and Monitor Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the training job\n",
    "print(f\"‚ñ∂Ô∏è Starting training job {job_id}...\")\n",
    "started_job = client.fine_tuning.jobs.start(job_id=job_id)\n",
    "print(f\"‚úÖ Training started! Status: {started_job.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor training progress\n",
    "def monitor_training(job_id, check_interval=60):\n",
    "   \"\"\"Monitor training job progress.\"\"\"\n",
    "   print(f\"üëÄ Monitoring job {job_id}...\")\n",
    "   print(f\"Checking every {check_interval} seconds. Press Ctrl+C to stop monitoring.\")\n",
    "\n",
    "   start_time = time.time()\n",
    "\n",
    "   try:\n",
    "       while True:\n",
    "           job = client.fine_tuning.jobs.get(job_id=job_id)\n",
    "           status = job.status\n",
    "           elapsed = time.time() - start_time\n",
    "\n",
    "           timestamp = time.strftime('%H:%M:%S')\n",
    "           print(f\"[{timestamp}] Status: {status} (Elapsed: {elapsed/60:.1f}m)\")\n",
    "\n",
    "           if status == \"SUCCESS\":\n",
    "               model_id = job.fine_tuned_model\n",
    "               print(f\"\\\\nüéâ Training completed successfully!\")\n",
    "               print(f\"Model ID: {model_id}\")\n",
    "               print(f\"Total time: {elapsed/60:.1f} minutes\")\n",
    "\n",
    "               # Save model info\n",
    "               model_info = {\n",
    "                   \"job_id\": job_id,\n",
    "                   \"model_id\": model_id,\n",
    "                   \"status\": status,\n",
    "                   \"training_time_minutes\": elapsed/60,\n",
    "                   \"completed_at\": time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "               }\n",
    "\n",
    "               with open(OUTPUT_DIR / \"model_info.json\", 'w') as f:\n",
    "                   json.dump(model_info, f, indent=2)\n",
    "\n",
    "               with open(OUTPUT_DIR / \"model_id.txt\", 'w') as f:\n",
    "                   f.write(model_id)\n",
    "\n",
    "               return model_id\n",
    "\n",
    "           elif status == \"FAILED\":\n",
    "               print(f\"\\\\n‚ùå Training failed\")\n",
    "               if hasattr(job, 'message'):\n",
    "                   print(f\"Error: {job.message}\")\n",
    "               return None\n",
    "\n",
    "           elif status in [\"RUNNING\", \"QUEUED\", \"VALIDATING\"]:\n",
    "               print(f\"   Training in progress...\")\n",
    "               time.sleep(check_interval)\n",
    "\n",
    "           else:\n",
    "               print(f\"   Unknown status: {status}\")\n",
    "               time.sleep(check_interval)\n",
    "\n",
    "   except KeyboardInterrupt:\n",
    "       print(f\"\\\\n‚è∏Ô∏è Monitoring stopped. Training continues in background.\")\n",
    "       print(f\"Job ID: {job_id}\")\n",
    "       return None\n",
    "\n",
    "# Start monitoring\n",
    "model_id = monitor_training(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_job = client.fine_tuning.jobs.get(job_id=created_jobs.id)\n",
    "print(json.dumps(retrieved_job.model_dump(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canceled_jobs = client.fine_tuning.jobs.cancel(job_id = created_jobs.id)\n",
    "print(canceled_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = client.fine_tuning.jobs.list()\n",
    "print(json.dumps(jobs.model_dump(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model ID if training is complete\n",
    "model_id_path = OUTPUT_DIR / \"model_id.txt\"\n",
    "if model_id_path.exists():\n",
    "    with open(model_id_path, 'r') as f:\n",
    "        model_id = f.read().strip()\n",
    "    print(f\"üìñ Loaded model ID: {model_id}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No trained model found. Please complete training first.\")\n",
    "    model_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T22:10:16.448150Z",
     "iopub.status.busy": "2025-06-23T22:10:16.447549Z",
     "iopub.status.idle": "2025-06-23T22:10:18.650171Z",
     "shell.execute_reply": "2025-06-23T22:10:18.649591Z",
     "shell.execute_reply.started": "2025-06-23T22:10:16.448112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing model with sample texts...\n",
      "\n",
      "üìù Test 1:\n",
      "Text: Roles: Contributor\n",
      "Title: Quartette f√ºr zwei Violinen, Viola...\n",
      "Classifier Response: {\n",
      "    \"id\": \"b189e1ddb3684911afb67502fec639a2\",\n",
      "    \"model\": \"ft:classifier:ministral-3b-latest:2bec22ef:20250623:ff14496d\",\n",
      "    \"results\": [\n",
      "        {\n",
      "            \"domain\": {\n",
      "                \"scores\": {\n",
      "                    \"Politics, Policy, and Government\": 1.0128285794053227e-05,\n",
      "                    \"Music, Sound, and Sonic Arts\": 0.9998216032981873,\n",
      "                    \"Philosophy and Ethics\": 5.092821993457619e-06,\n",
      "                    \"History, Heritage, and Memory\": 3.392550979697262e-06,\n",
      "                    \"Media, Journalism, and Communication\": 9.420773494639434e-07,\n",
      "                    \"Mathematics and Quantitative Sciences\": 2.4056787424342474e-06,\n",
      "                    \"Law, Justice, and Jurisprudence\": 3.611351530707907e-06,\n",
      "                    \"Performing Arts and Media\": 1.952278398675844e-05,\n",
      "                    \"Military, Security, and Defense\": 3.611351530707907e-06,\n",
      "                    \"Sciences, Research, and Discovery\": 2.2599260773858987e-06,\n",
      "                    \"Visual Arts and Design\": 2.144158133887686e-05,\n",
      "                    \"Social Reform, Advocacy, and Activism\": 2.4056787424342474e-06,\n",
      "                    \"Education, Pedagogy, and Learning\": 1.184116626973264e-05,\n",
      "                    \"Cultural Studies, Area Studies, and Social Sciences\": 3.844264028884936e-06,\n",
      "                    \"Natural Sciences\": 2.5608317173464457e-06,\n",
      "                    \"Arts, Culture, and Creative Expression\": 1.8735445337370038e-06,\n",
      "                    \"Documentary and Technical Arts\": 3.320936957607046e-05,\n",
      "                    \"Economics, Business, and Finance\": 1.067513494490413e-06,\n",
      "                    \"Medicine, Health, and Clinical Sciences\": 9.221909749612678e-06,\n",
      "                    \"Agriculture, Environment, and Sustainability\": 4.4500580997919315e-07,\n",
      "                    \"Literature and Narrative Arts\": 2.6684481781558134e-05,\n",
      "                    \"Applied Sciences, Technology, and Engineering\": 4.78426409245003e-06,\n",
      "                    \"Religion, Theology, and Spirituality\": 5.770923053205479e-06,\n",
      "                    \"Language, Linguistics, and Communication\": 2.2599260773858987e-06\n",
      "                }\n",
      "            },\n",
      "            \"parent_category\": {\n",
      "                \"scores\": {\n",
      "                    \"Arts, Culture, and Creative Expression\": 1.0,\n",
      "                    \"Sciences, Research, and Discovery\": 1.8189616479702408e-09,\n",
      "                    \"Society, Governance, and Public Life\": 3.364740708278191e-10,\n",
      "                    \"Humanities, Thought, and Interpretation\": 8.152020392060422e-09\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "üìù Test 2:\n",
      "Text: Roles: Contributor\n",
      "Title: John Wesley's Sunday service of th...\n",
      "Classifier Response: {\n",
      "    \"id\": \"d95210003fd345948f0cd59e8991131b\",\n",
      "    \"model\": \"ft:classifier:ministral-3b-latest:2bec22ef:20250623:ff14496d\",\n",
      "    \"results\": [\n",
      "        {\n",
      "            \"domain\": {\n",
      "                \"scores\": {\n",
      "                    \"Politics, Policy, and Government\": 8.579173140788043e-07,\n",
      "                    \"Music, Sound, and Sonic Arts\": 1.6536789644305827e-06,\n",
      "                    \"Philosophy and Ethics\": 8.764177295006448e-08,\n",
      "                    \"History, Heritage, and Memory\": 6.47590013613808e-07,\n",
      "                    \"Media, Journalism, and Communication\": 1.6373638800359913e-07,\n",
      "                    \"Mathematics and Quantitative Sciences\": 7.734359286359904e-08,\n",
      "                    \"Law, Justice, and Jurisprudence\": 1.1253426634993957e-07,\n",
      "                    \"Performing Arts and Media\": 4.139904419275808e-08,\n",
      "                    \"Military, Security, and Defense\": 4.139904419275808e-08,\n",
      "                    \"Sciences, Research, and Discovery\": 3.6534526515197285e-08,\n",
      "                    \"Visual Arts and Design\": 4.691126420652836e-08,\n",
      "                    \"Social Reform, Advocacy, and Activism\": 3.4662994607970177e-07,\n",
      "                    \"Education, Pedagogy, and Learning\": 1.9142724738685502e-07,\n",
      "                    \"Cultural Studies, Area Studies, and Social Sciences\": 4.5921004243609786e-07,\n",
      "                    \"Natural Sciences\": 8.233182313688303e-08,\n",
      "                    \"Arts, Culture, and Creative Expression\": 2.1024168006533728e-07,\n",
      "                    \"Documentary and Technical Arts\": 5.043435749030323e-07,\n",
      "                    \"Economics, Business, and Finance\": 2.0377322584863578e-07,\n",
      "                    \"Medicine, Health, and Clinical Sciences\": 6.68146697080374e-07,\n",
      "                    \"Agriculture, Environment, and Sustainability\": 8.233182313688303e-08,\n",
      "                    \"Literature and Narrative Arts\": 8.05938668690942e-07,\n",
      "                    \"Applied Sciences, Technology, and Engineering\": 2.5359989308526565e-07,\n",
      "                    \"Religion, Theology, and Spirituality\": 0.9999918937683105,\n",
      "                    \"Language, Linguistics, and Communication\": 3.927831642158708e-07\n",
      "                }\n",
      "            },\n",
      "            \"parent_category\": {\n",
      "                \"scores\": {\n",
      "                    \"Arts, Culture, and Creative Expression\": 2.4579935598012526e-07,\n",
      "                    \"Sciences, Research, and Discovery\": 2.998960191291644e-09,\n",
      "                    \"Society, Governance, and Public Life\": 2.358864925611215e-08,\n",
      "                    \"Humanities, Thought, and Interpretation\": 0.9999997615814209\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "üìù Test 3:\n",
      "Text: Roles: Contributor\n",
      "Title: The owl of Minerva: poems\n",
      "Attribut...\n",
      "Classifier Response: {\n",
      "    \"id\": \"8ddcecd7d5e34498bc43abc0cdfefcc2\",\n",
      "    \"model\": \"ft:classifier:ministral-3b-latest:2bec22ef:20250623:ff14496d\",\n",
      "    \"results\": [\n",
      "        {\n",
      "            \"domain\": {\n",
      "                \"scores\": {\n",
      "                    \"Politics, Policy, and Government\": 4.63683591078734e-06,\n",
      "                    \"Music, Sound, and Sonic Arts\": 1.2216436516609974e-05,\n",
      "                    \"Philosophy and Ethics\": 4.683038787334226e-05,\n",
      "                    \"History, Heritage, and Memory\": 4.494175755098695e-06,\n",
      "                    \"Media, Journalism, and Communication\": 6.337803824862931e-06,\n",
      "                    \"Mathematics and Quantitative Sciences\": 1.5531456938333577e-06,\n",
      "                    \"Law, Justice, and Jurisprudence\": 2.2598135274165543e-06,\n",
      "                    \"Performing Arts and Media\": 7.644850484211929e-06,\n",
      "                    \"Military, Security, and Defense\": 7.644850484211929e-06,\n",
      "                    \"Sciences, Research, and Discovery\": 2.2598135274165543e-06,\n",
      "                    \"Visual Arts and Design\": 2.9305707357707433e-05,\n",
      "                    \"Social Reform, Advocacy, and Activism\": 5.770635652879719e-06,\n",
      "                    \"Education, Pedagogy, and Learning\": 8.937736311054323e-06,\n",
      "                    \"Cultural Studies, Area Studies, and Social Sciences\": 3.647154153441079e-05,\n",
      "                    \"Natural Sciences\": 8.396225894102827e-06,\n",
      "                    \"Arts, Culture, and Creative Expression\": 9.420304536433832e-07,\n",
      "                    \"Documentary and Technical Arts\": 8.137900294968858e-06,\n",
      "                    \"Economics, Business, and Finance\": 3.611171450756956e-06,\n",
      "                    \"Medicine, Health, and Clinical Sciences\": 3.844072580250213e-06,\n",
      "                    \"Agriculture, Environment, and Sustainability\": 6.082205459279066e-07,\n",
      "                    \"Literature and Narrative Arts\": 0.999771773815155,\n",
      "                    \"Applied Sciences, Technology, and Engineering\": 3.3923820410564076e-06,\n",
      "                    \"Religion, Theology, and Spirituality\": 1.2604226867551915e-05,\n",
      "                    \"Language, Linguistics, and Communication\": 1.0449271030665841e-05\n",
      "                }\n",
      "            },\n",
      "            \"parent_category\": {\n",
      "                \"scores\": {\n",
      "                    \"Arts, Culture, and Creative Expression\": 0.9999984502792358,\n",
      "                    \"Sciences, Research, and Discovery\": 5.3157773294287836e-08,\n",
      "                    \"Society, Governance, and Public Life\": 4.4069341953445473e-08,\n",
      "                    \"Humanities, Thought, and Interpretation\": 1.5534978956566192e-06\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "üìù Test 4:\n",
      "Text: Roles: Creator\n",
      "Title: Archaeology and photography : the earl...\n",
      "Classifier Response: {\n",
      "    \"id\": \"d337d4d0da134fd2880a9ab5d0e9925b\",\n",
      "    \"model\": \"ft:classifier:ministral-3b-latest:2bec22ef:20250623:ff14496d\",\n",
      "    \"results\": [\n",
      "        {\n",
      "            \"domain\": {\n",
      "                \"scores\": {\n",
      "                    \"Politics, Policy, and Government\": 1.786459506547544e-05,\n",
      "                    \"Music, Sound, and Sonic Arts\": 1.3912960639572702e-05,\n",
      "                    \"Philosophy and Ethics\": 0.0006497390568256378,\n",
      "                    \"History, Heritage, and Memory\": 0.2693897783756256,\n",
      "                    \"Media, Journalism, and Communication\": 0.00021763531549368054,\n",
      "                    \"Mathematics and Quantitative Sciences\": 3.1044010029290803e-06,\n",
      "                    \"Law, Justice, and Jurisprudence\": 4.2854931962210685e-05,\n",
      "                    \"Performing Arts and Media\": 0.00019206249271519482,\n",
      "                    \"Military, Security, and Defense\": 3.1353338272310793e-05,\n",
      "                    \"Sciences, Research, and Discovery\": 3.781934719881974e-05,\n",
      "                    \"Visual Arts and Design\": 0.7181137800216675,\n",
      "                    \"Social Reform, Advocacy, and Activism\": 0.00017487487639300525,\n",
      "                    \"Education, Pedagogy, and Learning\": 6.637501792283729e-05,\n",
      "                    \"Cultural Studies, Area Studies, and Social Sciences\": 0.00047535920748487115,\n",
      "                    \"Natural Sciences\": 0.0023398001212626696,\n",
      "                    \"Arts, Culture, and Creative Expression\": 1.9016761143575422e-05,\n",
      "                    \"Documentary and Technical Arts\": 0.006985352840274572,\n",
      "                    \"Economics, Business, and Finance\": 7.927365913928952e-06,\n",
      "                    \"Medicine, Health, and Clinical Sciences\": 0.0003370801860000938,\n",
      "                    \"Agriculture, Environment, and Sustainability\": 0.00013619269884657115,\n",
      "                    \"Literature and Narrative Arts\": 0.00013200248940847814,\n",
      "                    \"Applied Sciences, Technology, and Engineering\": 0.0003267092979513109,\n",
      "                    \"Religion, Theology, and Spirituality\": 4.2854931962210685e-05,\n",
      "                    \"Language, Linguistics, and Communication\": 0.00024661311181262136\n",
      "                }\n",
      "            },\n",
      "            \"parent_category\": {\n",
      "                \"scores\": {\n",
      "                    \"Arts, Culture, and Creative Expression\": 0.9952378273010254,\n",
      "                    \"Sciences, Research, and Discovery\": 1.6110754586406983e-05,\n",
      "                    \"Society, Governance, and Public Life\": 6.185187118035174e-08,\n",
      "                    \"Humanities, Thought, and Interpretation\": 0.00474588805809617\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "üìù Test 5:\n",
      "Text: Roles: Creator\n",
      "Title: Shakespeare, education and pedagogy : ...\n",
      "Classifier Response: {\n",
      "    \"id\": \"0d246f4d8c684515a52caaec0161ff06\",\n",
      "    \"model\": \"ft:classifier:ministral-3b-latest:2bec22ef:20250623:ff14496d\",\n",
      "    \"results\": [\n",
      "        {\n",
      "            \"domain\": {\n",
      "                \"scores\": {\n",
      "                    \"Politics, Policy, and Government\": 3.0584399723920797e-07,\n",
      "                    \"Music, Sound, and Sonic Arts\": 5.421214154921472e-06,\n",
      "                    \"Philosophy and Ethics\": 1.0449663932377007e-05,\n",
      "                    \"History, Heritage, and Memory\": 3.2556923201809695e-07,\n",
      "                    \"Media, Journalism, and Communication\": 1.3004817446926609e-05,\n",
      "                    \"Mathematics and Quantitative Sciences\": 6.082433969822887e-07,\n",
      "                    \"Law, Justice, and Jurisprudence\": 6.474717224591586e-07,\n",
      "                    \"Performing Arts and Media\": 4.5391272578854114e-05,\n",
      "                    \"Military, Security, and Defense\": 3.927114562429779e-07,\n",
      "                    \"Sciences, Research, and Discovery\": 4.180391783847881e-07,\n",
      "                    \"Visual Arts and Design\": 2.9017671749898e-06,\n",
      "                    \"Social Reform, Advocacy, and Activism\": 6.892300348226854e-07,\n",
      "                    \"Education, Pedagogy, and Learning\": 6.0133665101602674e-05,\n",
      "                    \"Cultural Studies, Area Studies, and Social Sciences\": 7.887820174801163e-06,\n",
      "                    \"Natural Sciences\": 7.264431189923926e-08,\n",
      "                    \"Arts, Culture, and Creative Expression\": 2.6990636570189963e-07,\n",
      "                    \"Documentary and Technical Arts\": 1.833973146858625e-05,\n",
      "                    \"Economics, Business, and Finance\": 1.602507836651057e-06,\n",
      "                    \"Medicine, Health, and Clinical Sciences\": 4.180391783847881e-07,\n",
      "                    \"Agriculture, Environment, and Sustainability\": 3.223571809485293e-08,\n",
      "                    \"Literature and Narrative Arts\": 0.9998093247413635,\n",
      "                    \"Applied Sciences, Technology, and Engineering\": 2.1020329654675152e-07,\n",
      "                    \"Religion, Theology, and Spirituality\": 1.00282386483741e-06,\n",
      "                    \"Language, Linguistics, and Communication\": 2.014225538005121e-05\n",
      "                }\n",
      "            },\n",
      "            \"parent_category\": {\n",
      "                \"scores\": {\n",
      "                    \"Arts, Culture, and Creative Expression\": 0.9998975992202759,\n",
      "                    \"Sciences, Research, and Discovery\": 1.3175165125556276e-10,\n",
      "                    \"Society, Governance, and Public Life\": 0.00010229984036413953,\n",
      "                    \"Humanities, Thought, and Interpretation\": 9.328538652653151e-08\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test classification function\n",
    "def classify_text(text, model_id):\n",
    "    \"\"\"Classify a single text using the trained model.\"\"\"\n",
    "    try:\n",
    "        response = client.classifiers.classify(\n",
    "            model=model_id,\n",
    "            inputs=[text]\n",
    "        )\n",
    "        \n",
    "        # result = response.results[0]\n",
    "        # classification = {}\n",
    "        \n",
    "        # for label_name, prediction in result.predictions.items():\n",
    "        #     if hasattr(prediction, 'value'):\n",
    "        #         classification[label_name] = prediction.value\n",
    "        #     else:\n",
    "        #         classification[label_name] = str(prediction)\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return {}\n",
    "\n",
    "model_id = \"ft:classifier:ministral-3b-latest:2bec22ef:20250623:ff14496d\"\n",
    "\n",
    "if model_id:\n",
    "    print(\"üß™ Testing model with sample texts...\")\n",
    "    \n",
    "    # Test with some examples\n",
    "    test_texts = [\n",
    "        \"Roles: Contributor\\nTitle: Quartette f√ºr zwei Violinen, Viola, Violoncell\\nSubjects: String quartets--Scores\",\n",
    "        \"Roles: Contributor\\nTitle: John Wesley's Sunday service of the Methodists\\nSubjects: Methodist Church--Liturgy--Texts\",\n",
    "        \"Roles: Contributor\\nTitle: The owl of Minerva: poems\\nAttribution: by James Laughlin\",\n",
    "        \"Roles: Creator\\nTitle: Archaeology and photography : the early years, 1868-1880\\nAttribution: [text] Ismeth Raheem\\nSubjects: Photography in archaeology\\nProvision information: Colombo : National Trust Sri Lanka, 2009\",\n",
    "        \"Roles: Creator\\nTitle: Shakespeare, education and pedagogy : representations, interactions and adaptations\\nAttribution: edited by Pamela Bickley and Jenny Stevens\\nSubjects: Shakespeare, William, 1564-1616--Criticism and interpretation; Shakespeare, William, 1564-1616--Study and teaching; Education in literature; Education\\nProvision information: Abingdon, Oxon ; New York, NY : Routledge, Taylor & Francis Group, 2023\"\n",
    "        \n",
    "    ]\n",
    "    \n",
    "    for i, text in enumerate(test_texts, 1):\n",
    "        print(f\"\\nüìù Test {i}:\")\n",
    "        print(f\"Text: {text[:60]}...\")\n",
    "        \n",
    "        classification = classify_text(text, model_id)\n",
    "        if classification:\n",
    "            # print(f\"Domains: {classification.get('domain', [])}\")\n",
    "            # print(f\"Parents: {classification.get('parent_category', [])}\")\n",
    "            print(\"Classifier Response:\", json.dumps(classification.model_dump(), indent=4))\n",
    "        else:\n",
    "            print(\"Classification failed\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Skipping tests (no trained model)\")\n",
    "\n",
    "\n",
    "# Classify the first test sample\n",
    "# classifier_response = client.classifiers.classify(\n",
    "#     model=retrieved_job.fine_tuned_model,\n",
    "#     inputs=[test_samples[0][\"text\"]],\n",
    "# )\n",
    "# print(\"Text:\", test_samples[0][\"text\"])\n",
    "# print(\"Classifier Response:\", json.dumps(classifier_response.model_dump(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance\n",
    "if model_id:\n",
    "    print(f\"üìä Evaluating model on {len(val_examples)} validation examples...\")\n",
    "    \n",
    "    correct_exact = 0\n",
    "    correct_partial = 0\n",
    "    total = len(val_examples)\n",
    "    \n",
    "    for i, example in enumerate(val_examples[:50]):  # Test first 50 for speed\n",
    "        if i % 10 == 0:\n",
    "            print(f\"  Progress: {i}/{min(50, total)}\")\n",
    "        \n",
    "        text = example['text']\n",
    "        true_domains = set(example['labels']['domain'])\n",
    "        \n",
    "        classification = classify_text(text, model_id)\n",
    "        if classification:\n",
    "            pred_domains = set(classification.get('domain', []))\n",
    "            \n",
    "            # Exact match\n",
    "            if true_domains == pred_domains:\n",
    "                correct_exact += 1\n",
    "            \n",
    "            # Partial match (any overlap)\n",
    "            if len(true_domains & pred_domains) > 0:\n",
    "                correct_partial += 1\n",
    "        \n",
    "        time.sleep(0.1)  # Rate limiting\n",
    "    \n",
    "    tested = min(50, total)\n",
    "    exact_accuracy = correct_exact / tested\n",
    "    partial_accuracy = correct_partial / tested\n",
    "    \n",
    "    print(f\"\\nüìà Evaluation Results (on {tested} examples):\")\n",
    "    print(f\"Exact match accuracy: {exact_accuracy:.3f} ({correct_exact}/{tested})\")\n",
    "    print(f\"Partial match accuracy: {partial_accuracy:.3f} ({correct_partial}/{tested})\")\n",
    "    \n",
    "    # Save results\n",
    "    eval_results = {\n",
    "        \"model_id\": model_id,\n",
    "        \"tested_examples\": tested,\n",
    "        \"exact_accuracy\": exact_accuracy,\n",
    "        \"partial_accuracy\": partial_accuracy,\n",
    "        \"evaluated_at\": time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    \n",
    "    with open(OUTPUT_DIR / \"evaluation_results.json\", 'w') as f:\n",
    "        json.dump(eval_results, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nüíæ Results saved to {OUTPUT_DIR / 'evaluation_results.json'}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Skipping evaluation (no trained model)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Integration with Entity Resolution Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create taxonomy dissimilarity calculator for entity resolution\n",
    "class MistralTaxonomyFeature:\n",
    "    \"\"\"Mistral-based taxonomy feature for entity resolution.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_id, entity_lookup):\n",
    "        self.model_id = model_id\n",
    "        self.entity_lookup = entity_lookup\n",
    "        self.cache = {}\n",
    "        self.client = client\n",
    "    \n",
    "    def get_classification(self, person_id):\n",
    "        \"\"\"Get classification for a person ID with caching.\"\"\"\n",
    "        if person_id in self.cache:\n",
    "            return self.cache[person_id]\n",
    "        \n",
    "        text = self.entity_lookup.get(person_id)\n",
    "        if not text:\n",
    "            return {}\n",
    "        \n",
    "        classification = classify_text(text, self.model_id)\n",
    "        self.cache[person_id] = classification\n",
    "        return classification\n",
    "    \n",
    "    def calculate_dissimilarity(self, person_id1, person_id2):\n",
    "        \"\"\"Calculate taxonomy dissimilarity between two entities.\"\"\"\n",
    "        class1 = self.get_classification(person_id1)\n",
    "        class2 = self.get_classification(person_id2)\n",
    "        \n",
    "        if not class1 or not class2:\n",
    "            return 0.5  # Neutral dissimilarity\n",
    "        \n",
    "        domains1 = set(class1.get('domain', []))\n",
    "        domains2 = set(class2.get('domain', []))\n",
    "        \n",
    "        if not domains1 or not domains2:\n",
    "            return 0.5\n",
    "        \n",
    "        # Calculate Jaccard dissimilarity\n",
    "        intersection = len(domains1 & domains2)\n",
    "        union = len(domains1 | domains2)\n",
    "        \n",
    "        if union == 0:\n",
    "            return 0.5\n",
    "        \n",
    "        similarity = intersection / union\n",
    "        dissimilarity = 1.0 - similarity\n",
    "        \n",
    "        return dissimilarity\n",
    "\n",
    "if model_id:\n",
    "    # Create feature calculator\n",
    "    taxonomy_feature = MistralTaxonomyFeature(model_id, entity_lookup)\n",
    "    print(\"üîß Taxonomy feature calculator created\")\n",
    "    \n",
    "    # Test with sample entity pairs\n",
    "    print(\"\\nüß™ Testing dissimilarity calculation:\")\n",
    "    sample_ids = list(entity_lookup.keys())[:5]\n",
    "    \n",
    "    for i in range(min(3, len(sample_ids)-1)):\n",
    "        id1, id2 = sample_ids[i], sample_ids[i+1]\n",
    "        dissimilarity = taxonomy_feature.calculate_dissimilarity(id1, id2)\n",
    "        print(f\"  {id1} vs {id2}: {dissimilarity:.3f}\")\n",
    "        time.sleep(0.2)  # Rate limiting\n",
    "    \n",
    "    print(\"\\n‚úÖ Ready for pipeline integration!\")\n",
    "    print(\"Use taxonomy_feature.calculate_dissimilarity(id1, id2) in your entity resolution pipeline\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Skipping integration demo (no trained model)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has:\n",
    "\n",
    "1. ‚úÖ Loaded and prepared your entity taxonomy data\n",
    "2. ‚úÖ Converted to Mistral's multi-label format\n",
    "3. ‚úÖ Uploaded training files to Mistral\n",
    "4. ‚úÖ Created and started fine-tuning job\n",
    "5. ‚úÖ Monitored training progress\n",
    "6. ‚úÖ Tested the trained model\n",
    "7. ‚úÖ Evaluated performance\n",
    "8. ‚úÖ Created integration components\n",
    "\n",
    "Your Mistral classifier is now ready to replace SetFit in your entity resolution pipeline!\n",
    "\n",
    "### Next Steps:\n",
    "- Replace `src/taxonomy_feature.py` with `MistralTaxonomyFeature`\n",
    "- Update your pipeline configuration\n",
    "- Test entity resolution performance\n",
    "- Monitor API usage and costs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
