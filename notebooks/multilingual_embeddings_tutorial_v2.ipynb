{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilingual Embeddings with Sentence Transformers and Weaviate\n",
    "\n",
    "This notebook demonstrates how to use the `paraphrase-multilingual-MiniLM-L12-v2` model to create semantic embeddings and index them in Weaviate for powerful similarity search capabilities.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will understand how to:\n",
    "1. Generate multilingual embeddings using sentence transformers\n",
    "2. Calculate and interpret similarity scores between text segments\n",
    "3. Set up a Weaviate vector database with proper schema configuration\n",
    "4. Index embeddings for efficient similarity search\n",
    "5. Perform semantic queries across different languages\n",
    "\n",
    "## Background: Why Multilingual Embeddings Matter\n",
    "\n",
    "Traditional keyword search works by matching exact words or phrases. This approach fails when:\n",
    "- Different languages describe the same concept\n",
    "- Synonyms or related terms are used instead of exact matches\n",
    "- Cultural or domain-specific terminology varies\n",
    "\n",
    "Multilingual embeddings solve these problems by mapping text from different languages into a shared semantic space where similar meanings cluster together, regardless of the specific words or language used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setting Up the Environment\n",
    "\n",
    "First, let's install the required packages and import the necessary libraries. We'll use the sentence-transformers library to work with the multilingual model and the Weaviate Python client for vector database operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run this once)\n",
    "# !pip install sentence-transformers weaviate-client numpy matplotlib seaborn\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import weaviate\n",
    "from weaviate.classes.config import Configure, Property, DataType\n",
    "from weaviate.classes.config import VectorDistances\n",
    "from weaviate.util import generate_uuid5\n",
    "from typing import List, Dict, Tuple\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress minor warnings for cleaner output\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(\"üìö Ready to explore multilingual embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Loading the Multilingual Model\n",
    "\n",
    "The `paraphrase-multilingual-MiniLM-L12-v2` model is specifically designed to understand semantic similarity across 50+ languages. It creates 384-dimensional embeddings that capture meaning rather than just word patterns.\n",
    "\n",
    "### Key Model Characteristics:\n",
    "- **Input limit**: 128 tokens (roughly 80-100 words)\n",
    "- **Output dimensions**: 384 floating-point numbers\n",
    "- **Languages supported**: 50+ including English, Spanish, French, German, Chinese, Arabic, and many others\n",
    "- **Optimization**: Trained specifically for paraphrase detection and semantic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the multilingual sentence transformer model\n",
    "# This will download the model on first run (~200MB)\n",
    "print(\"üîÑ Loading multilingual sentence transformer model...\")\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Display model information\n",
    "print(f\"‚úÖ Model loaded successfully!\")\n",
    "print(f\"üìè Model produces {model.get_sentence_embedding_dimension()} dimensional embeddings\")\n",
    "print(f\"üî§ Maximum sequence length: {model.max_seq_length} tokens\")\n",
    "print(f\"üåç Supports 50+ languages including major European, Asian, and Arabic languages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Creating Your First Embeddings\n",
    "\n",
    "Let's start with a simple example to understand how text gets converted into numerical vectors. We'll use bibliographic examples similar to what you might encounter in library catalogs, demonstrating the model's ability to understand academic and cultural content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some example texts in different languages but related meanings\n",
    "# These examples simulate bibliographic records you might find in a library catalog\n",
    "example_texts = [\n",
    "    \"Franz Schubert: Symphony No. 8 in B minor (Unfinished Symphony)\",  # English\n",
    "    \"Franz Schubert: Symphonie n¬∞ 8 en si mineur (Inachev√©e)\",          # French\n",
    "    \"Franz Schubert: Sinfonie Nr. 8 in h-Moll (Unvollendete)\",          # German\n",
    "    \"Franz Schubert: Sinfon√≠a No. 8 en si menor (Inconclusa)\",          # Spanish\n",
    "    \"William Shakespeare: Romeo and Juliet - English drama\",             # English literature\n",
    "    \"Digital preservation of medieval manuscripts\",                      # Library science\n",
    "    \"Artificial intelligence applications in cataloging\",                # Modern library tech\n",
    "]\n",
    "\n",
    "# Generate embeddings for all texts\n",
    "print(\"üîÑ Generating embeddings for example texts...\")\n",
    "embeddings = model.encode(example_texts)\n",
    "\n",
    "print(f\"‚úÖ Generated {len(embeddings)} embeddings\")\n",
    "print(f\"üìä Each embedding has {embeddings[0].shape[0]} dimensions\")\n",
    "print(f\"üíæ Total size: {embeddings.nbytes:,} bytes\")\n",
    "\n",
    "# Let's examine the first embedding to understand what we're working with\n",
    "print(f\"\\nüîç First embedding (truncated to first 10 dimensions):\")\n",
    "print(f\"   {embeddings[0][:10]}\")\n",
    "print(f\"\\nüìà Value range: [{embeddings[0].min():.3f}, {embeddings[0].max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Understanding Similarity Through Comparison\n",
    "\n",
    "Now let's explore how the embeddings capture semantic relationships. We'll calculate cosine similarity between different text pairs to see how the model understands meaning across languages and topics.\n",
    "\n",
    "### Cosine Similarity Explained:\n",
    "- **Range**: -1 to 1 (though sentence transformers typically produce 0 to 1)\n",
    "- **Interpretation**: \n",
    "  - 1.0 = identical meaning\n",
    "  - 0.7-0.9 = very similar\n",
    "  - 0.5-0.7 = moderately similar\n",
    "  - 0.0-0.5 = dissimilar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity matrix for all text pairs\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "# Create a more readable display with text labels\n",
    "# Let's create shortened labels for better visualization\n",
    "labels = [\n",
    "    \"Schubert Symphony (EN)\",\n",
    "    \"Schubert Symphony (FR)\", \n",
    "    \"Schubert Symphony (DE)\",\n",
    "    \"Schubert Symphony (ES)\",\n",
    "    \"Shakespeare Romeo (EN)\",\n",
    "    \"Medieval manuscripts\",\n",
    "    \"AI in cataloging\"\n",
    "]\n",
    "\n",
    "# Create a DataFrame for better display\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=labels, columns=labels)\n",
    "\n",
    "# Display the similarity matrix\n",
    "print(\"üéØ Semantic Similarity Matrix (Cosine Similarity)\")\n",
    "print(\"=\" * 55)\n",
    "print(similarity_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap visualization for better understanding\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(similarity_df, \n",
    "            annot=True, \n",
    "            cmap='coolwarm', \n",
    "            center=0.5,\n",
    "            square=True,\n",
    "            fmt='.3f',\n",
    "            cbar_kws={'label': 'Cosine Similarity'})\n",
    "\n",
    "plt.title('Semantic Similarity Across Languages and Topics\\n'\n",
    "          'Red = High Similarity, Blue = Low Similarity', \n",
    "          fontsize=14, pad=20)\n",
    "plt.xlabel('Texts', fontsize=12)\n",
    "plt.ylabel('Texts', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze some interesting pairs\n",
    "print(\"\\nüîç Analysis of Key Similarity Patterns:\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Cross-language similarities for the same work\n",
    "schubert_pairs = [\n",
    "    (0, 1, \"English ‚Üí French\"),\n",
    "    (0, 2, \"English ‚Üí German\"), \n",
    "    (0, 3, \"English ‚Üí Spanish\")\n",
    "]\n",
    "\n",
    "print(\"üìö Same work, different languages:\")\n",
    "for i, j, desc in schubert_pairs:\n",
    "    sim = similarity_matrix[i, j]\n",
    "    print(f\"   {desc}: {sim:.3f}\")\n",
    "\n",
    "# Cross-topic similarities\n",
    "print(\"\\nüé≠ Different topics:\")\n",
    "topic_pairs = [\n",
    "    (0, 4, \"Schubert ‚Üí Shakespeare\"),\n",
    "    (0, 5, \"Schubert ‚Üí Medieval manuscripts\"),\n",
    "    (5, 6, \"Medieval manuscripts ‚Üí AI cataloging\")\n",
    "]\n",
    "\n",
    "for i, j, desc in topic_pairs:\n",
    "    sim = similarity_matrix[i, j]\n",
    "    print(f\"   {desc}: {sim:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Setting Up Weaviate Vector Database\n",
    "\n",
    "Now let's set up Weaviate to store and search our embeddings efficiently. Weaviate is a vector database that can perform fast similarity searches across millions of vectors.\n",
    "\n",
    "### Why Use a Vector Database?\n",
    "- **Scale**: Handle millions of embeddings efficiently\n",
    "- **Speed**: Sub-second similarity search\n",
    "- **Filtering**: Combine vector similarity with traditional filters\n",
    "- **Real-time**: Add and update embeddings dynamically\n",
    "\n",
    "**Note**: This example assumes Weaviate is running locally on port 8080. For production use, you'd typically use Weaviate Cloud Services or a dedicated server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Weaviate (adjust URL if your instance is elsewhere)\n",
    "# This assumes you have Weaviate running locally with Docker:\n",
    "# docker run -p 8080:8080 -e QUERY_DEFAULTS_LIMIT=25 cr.weaviate.io/semitechnologies/weaviate:1.25.1\n",
    "\n",
    "try:\n",
    "    # Initialize Weaviate client with connection parameters\n",
    "    from weaviate.connect import ConnectionParams\n",
    "    \n",
    "    connection_params = ConnectionParams.from_params(\n",
    "        http_host=\"localhost\",\n",
    "        http_port=8080,\n",
    "        http_secure=False,\n",
    "        grpc_host=\"localhost\",\n",
    "        grpc_port=50051,\n",
    "        grpc_secure=False\n",
    "    )\n",
    "    \n",
    "    client = weaviate.WeaviateClient(connection_params=connection_params)\n",
    "    client.connect()\n",
    "    \n",
    "    print(\"‚úÖ Connected to Weaviate successfully!\")\n",
    "    \n",
    "    # Check if Weaviate is ready\n",
    "    if client.is_ready():\n",
    "        print(\"üü¢ Weaviate is ready for operations\")\n",
    "    else:\n",
    "        print(\"üü° Weaviate connection established but may not be fully ready\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to connect to Weaviate: {str(e)}\")\n",
    "    print(\"üí° Make sure Weaviate is running locally on port 8080\")\n",
    "    print(\"   Docker command: docker run -p 8080:8080 cr.weaviate.io/semitechnologies/weaviate:1.25.1\")\n",
    "    # For the notebook to continue, we'll create a mock client\n",
    "    client = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Creating a Schema for Multilingual Documents\n",
    "\n",
    "Before we can store our embeddings, we need to define a schema that describes the structure of our data. In Weaviate, this is called a \"collection\" and it defines what properties each object will have and how vectors should be handled.\n",
    "\n",
    "### Schema Design Considerations:\n",
    "- **Properties**: What metadata do we want to store alongside vectors?\n",
    "- **Vector configuration**: Dimension size, distance metric, indexing parameters\n",
    "- **Indexing strategy**: How to optimize for query performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for our multilingual document collection\n",
    "if client is not None:\n",
    "    try:\n",
    "        # First, let's clean up any existing collection with the same name\n",
    "        try:\n",
    "            client.collections.delete(\"MultilingualDocument\")\n",
    "            print(\"üßπ Cleaned up existing collection\")\n",
    "        except:\n",
    "            pass  # Collection didn't exist, which is fine\n",
    "        \n",
    "        # Create a new collection for multilingual documents\n",
    "        print(\"üîÑ Creating MultilingualDocument collection...\")\n",
    "        \n",
    "        collection = client.collections.create(\n",
    "            name=\"MultilingualDocument\",\n",
    "            description=\"Collection for multilingual bibliographic documents with semantic embeddings\",\n",
    "            \n",
    "            # Configure vector index for optimal performance\n",
    "            vector_index_config=Configure.VectorIndex.hnsw(\n",
    "                ef=128,                    # Higher ef = better recall, slower queries\n",
    "                max_connections=64,        # Higher = better connectivity, more memory\n",
    "                ef_construction=128,       # Higher = better index quality, slower build\n",
    "                distance_metric=VectorDistances.COSINE  # Use cosine distance for semantic similarity\n",
    "            ),\n",
    "            \n",
    "            # Define properties that will be stored with each document\n",
    "            properties=[\n",
    "                Property(\n",
    "                    name=\"text\", \n",
    "                    data_type=DataType.TEXT,\n",
    "                    description=\"The original text content\"\n",
    "                ),\n",
    "                Property(\n",
    "                    name=\"language\", \n",
    "                    data_type=DataType.TEXT,\n",
    "                    description=\"Language code (en, fr, de, es, etc.)\"\n",
    "                ),\n",
    "                Property(\n",
    "                    name=\"category\", \n",
    "                    data_type=DataType.TEXT,\n",
    "                    description=\"Document category (music, literature, library_science)\"\n",
    "                ),\n",
    "                Property(\n",
    "                    name=\"author\", \n",
    "                    data_type=DataType.TEXT,\n",
    "                    description=\"Author or creator name\"\n",
    "                ),\n",
    "                Property(\n",
    "                    name=\"embedding_model\", \n",
    "                    data_type=DataType.TEXT,\n",
    "                    description=\"Model used to generate the embedding\"\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Collection created successfully!\")\n",
    "        print(f\"üìä Collection name: {collection.name}\")\n",
    "        print(f\"üìù Description: {collection.description}\")\n",
    "        print(f\"üéØ Vector distance metric: Cosine\")\n",
    "        print(f\"üìè Expected vector dimensions: 384\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating collection: {str(e)}\")\n",
    "        collection = None\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipping schema creation (Weaviate not connected)\")\n",
    "    collection = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Indexing Documents with Embeddings\n",
    "\n",
    "Now we'll take our example texts, generate their embeddings, and store them in Weaviate along with useful metadata. This process is called \"indexing\" and it makes our documents searchable through semantic similarity.\n",
    "\n",
    "### Indexing Strategy:\n",
    "1. **Prepare data**: Organize texts with metadata\n",
    "2. **Generate embeddings**: Use our sentence transformer model\n",
    "3. **Batch insert**: Efficiently store multiple documents at once\n",
    "4. **Verify storage**: Confirm everything was indexed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare our example documents with rich metadata\n",
    "documents = [\n",
    "    {\n",
    "        \"text\": \"Franz Schubert: Symphony No. 8 in B minor (Unfinished Symphony)\",\n",
    "        \"language\": \"en\",\n",
    "        \"category\": \"music\",\n",
    "        \"author\": \"Franz Schubert\",\n",
    "        \"embedding_model\": \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Franz Schubert: Symphonie n¬∞ 8 en si mineur (Inachev√©e)\",\n",
    "        \"language\": \"fr\",\n",
    "        \"category\": \"music\",\n",
    "        \"author\": \"Franz Schubert\",\n",
    "        \"embedding_model\": \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Franz Schubert: Sinfonie Nr. 8 in h-Moll (Unvollendete)\",\n",
    "        \"language\": \"de\",\n",
    "        \"category\": \"music\",\n",
    "        \"author\": \"Franz Schubert\",\n",
    "        \"embedding_model\": \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Franz Schubert: Sinfon√≠a No. 8 en si menor (Inconclusa)\",\n",
    "        \"language\": \"es\",\n",
    "        \"category\": \"music\",\n",
    "        \"author\": \"Franz Schubert\",\n",
    "        \"embedding_model\": \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"William Shakespeare: Romeo and Juliet - English drama\",\n",
    "        \"language\": \"en\",\n",
    "        \"category\": \"literature\",\n",
    "        \"author\": \"William Shakespeare\",\n",
    "        \"embedding_model\": \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Digital preservation of medieval manuscripts\",\n",
    "        \"language\": \"en\",\n",
    "        \"category\": \"library_science\",\n",
    "        \"author\": \"Unknown\",\n",
    "        \"embedding_model\": \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Artificial intelligence applications in cataloging\",\n",
    "        \"language\": \"en\",\n",
    "        \"category\": \"library_science\",\n",
    "        \"author\": \"Unknown\",\n",
    "        \"embedding_model\": \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"üìö Prepared {len(documents)} documents for indexing\")\n",
    "\n",
    "# Generate embeddings for all documents\n",
    "print(\"üîÑ Generating embeddings for all documents...\")\n",
    "document_texts = [doc[\"text\"] for doc in documents]\n",
    "document_embeddings = model.encode(document_texts)\n",
    "\n",
    "print(f\"‚úÖ Generated {len(document_embeddings)} embeddings\")\n",
    "print(f\"üìä Embedding shape: {document_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index documents in Weaviate with batch operations for efficiency\n",
    "if client is not None and collection is not None:\n",
    "    try:\n",
    "        print(\"üîÑ Indexing documents in Weaviate...\")\n",
    "        indexed_count = 0\n",
    "        \n",
    "        # Use batch operations for efficient indexing\n",
    "        # Fixed-size batches help manage memory and provide better error handling\n",
    "        with collection.batch.fixed_size(batch_size=100) as batch_writer:\n",
    "            for i, (document, embedding) in enumerate(zip(documents, document_embeddings)):\n",
    "                try:\n",
    "                    # Generate a unique UUID for this document\n",
    "                    # Using the text content to ensure consistency across runs\n",
    "                    uuid_input = f\"{document['text']}_{document['language']}\"\n",
    "                    uuid = generate_uuid5(uuid_input)\n",
    "                    \n",
    "                    # Prepare the vector data\n",
    "                    # Ensure the embedding is in the right format (list of floats)\n",
    "                    vector_data = embedding.tolist() if hasattr(embedding, 'tolist') else list(embedding)\n",
    "                    \n",
    "                    # Add the object to Weaviate\n",
    "                    batch_writer.add_object(\n",
    "                        properties=document,  # All the metadata we defined\n",
    "                        uuid=uuid,           # Unique identifier\n",
    "                        vector=vector_data   # The 384-dimensional embedding\n",
    "                    )\n",
    "                    \n",
    "                    indexed_count += 1\n",
    "                    print(f\"   üìÑ Indexed: {document['text'][:50]}... ({document['language']})\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ùå Error indexing document {i}: {str(e)}\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ Successfully indexed {indexed_count}/{len(documents)} documents!\")\n",
    "        \n",
    "        # Verify the collection has the expected number of objects\n",
    "        try:\n",
    "            result = collection.aggregate.over_all(total_count=True)\n",
    "            total_objects = result.total_count\n",
    "            print(f\"üìä Collection now contains {total_objects} total objects\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not verify object count: {str(e)}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during indexing: {str(e)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipping indexing (Weaviate not connected or collection not created)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Performing Semantic Queries\n",
    "\n",
    "Now comes the exciting part! We'll perform semantic searches to find documents based on meaning rather than exact keyword matches. This demonstrates the power of vector databases for multilingual content discovery.\n",
    "\n",
    "### Query Types We'll Explore:\n",
    "1. **Cross-language search**: Query in one language, find results in others\n",
    "2. **Conceptual search**: Find related concepts even with different terminology\n",
    "3. **Similarity with filtering**: Combine semantic similarity with metadata filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_semantic_search(query_text: str, limit: int = 5, show_details: bool = True) -> List[Dict]:\n",
    "    \"\"\"Perform a semantic search query against our indexed documents.\n",
    "    \n",
    "    Args:\n",
    "        query_text: The text to search for\n",
    "        limit: Maximum number of results to return\n",
    "        show_details: Whether to print detailed results\n",
    "        \n",
    "    Returns:\n",
    "        List of search results with metadata and similarity scores\n",
    "    \"\"\"\n",
    "    if client is None or collection is None:\n",
    "        print(\"‚ö†Ô∏è Cannot perform search (Weaviate not connected)\")\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # Generate embedding for the query\n",
    "        query_embedding = model.encode([query_text])[0]\n",
    "        \n",
    "        if show_details:\n",
    "            print(f\"üîç Searching for: '{query_text}'\")\n",
    "            print(f\"üìä Query embedding shape: {query_embedding.shape}\")\n",
    "            print(\"=\" * 60)\n",
    "        \n",
    "        # Perform vector similarity search\n",
    "        response = collection.query.near_vector(\n",
    "            near_vector=query_embedding.tolist(),\n",
    "            limit=limit,\n",
    "            return_metadata=['distance']  # Include similarity distance in results\n",
    "        )\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        if show_details:\n",
    "            print(f\"üìã Found {len(response.objects)} results:\\n\")\n",
    "        \n",
    "        for i, obj in enumerate(response.objects, 1):\n",
    "            # Calculate similarity score from distance\n",
    "            # Weaviate returns cosine distance, we convert to similarity\n",
    "            distance = obj.metadata.distance\n",
    "            similarity = 1 - distance  # Convert distance to similarity\n",
    "            \n",
    "            result = {\n",
    "                'rank': i,\n",
    "                'text': obj.properties['text'],\n",
    "                'language': obj.properties['language'],\n",
    "                'category': obj.properties['category'],\n",
    "                'author': obj.properties['author'],\n",
    "                'similarity': similarity,\n",
    "                'distance': distance\n",
    "            }\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "            if show_details:\n",
    "                print(f\"   {i}. [{result['language'].upper()}] {result['text']}\")\n",
    "                print(f\"      üìö Category: {result['category']} | ‚úçÔ∏è Author: {result['author']}\")\n",
    "                print(f\"      üéØ Similarity: {similarity:.3f} | üìè Distance: {distance:.3f}\")\n",
    "                print()\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during search: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# Test with different types of queries\n",
    "test_queries = [\n",
    "    \"Classical music symphony\",           # Should find Schubert works across languages\n",
    "    \"M√∫sica cl√°sica sinfon√≠a\",            # Spanish query for same concept\n",
    "    \"Shakespeare theatrical works\",       # Should find Romeo and Juliet\n",
    "    \"Library digital technology\",         # Should find library science documents\n",
    "]\n",
    "\n",
    "print(\"üöÄ Testing semantic search capabilities...\\n\")\n",
    "\n",
    "for query in test_queries:\n",
    "    results = perform_semantic_search(query, limit=3)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Advanced Querying with Filters\n",
    "\n",
    "Vector databases shine when you combine semantic similarity with traditional filtering. Let's explore how to search for semantically similar content while applying filters based on metadata like language, category, or author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_semantic_search(query_text: str, language_filter: str = None, \n",
    "                           category_filter: str = None, limit: int = 5) -> List[Dict]:\n",
    "    \"\"\"Perform semantic search with metadata filters.\n",
    "    \n",
    "    Args:\n",
    "        query_text: The text to search for\n",
    "        language_filter: Filter by specific language (e.g., 'en', 'fr')\n",
    "        category_filter: Filter by category (e.g., 'music', 'literature')\n",
    "        limit: Maximum number of results\n",
    "        \n",
    "    Returns:\n",
    "        List of filtered search results\n",
    "    \"\"\"\n",
    "    if client is None or collection is None:\n",
    "        print(\"‚ö†Ô∏è Cannot perform search (Weaviate not connected)\")\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # Generate embedding for the query\n",
    "        query_embedding = model.encode([query_text])[0]\n",
    "        \n",
    "        # Build the base query\n",
    "        query_builder = collection.query.near_vector(\n",
    "            near_vector=query_embedding.tolist(),\n",
    "            limit=limit,\n",
    "            return_metadata=['distance']\n",
    "        )\n",
    "        \n",
    "        # Apply filters if specified\n",
    "        if language_filter or category_filter:\n",
    "            from weaviate.classes.query import Filter\n",
    "            \n",
    "            filters = []\n",
    "            if language_filter:\n",
    "                filters.append(Filter.by_property(\"language\").equal(language_filter))\n",
    "            if category_filter:\n",
    "                filters.append(Filter.by_property(\"category\").equal(category_filter))\n",
    "            \n",
    "            # Combine filters with AND logic\n",
    "            if len(filters) == 1:\n",
    "                combined_filter = filters[0]\n",
    "            else:\n",
    "                combined_filter = Filter.all_of(filters)\n",
    "            \n",
    "            query_builder = query_builder.where(combined_filter)\n",
    "        \n",
    "        # Execute the query\n",
    "        response = query_builder\n",
    "        \n",
    "        # Format filter description\n",
    "        filter_desc = []\n",
    "        if language_filter:\n",
    "            filter_desc.append(f\"language={language_filter}\")\n",
    "        if category_filter:\n",
    "            filter_desc.append(f\"category={category_filter}\")\n",
    "        \n",
    "        filter_str = \" AND \".join(filter_desc) if filter_desc else \"no filters\"\n",
    "        \n",
    "        print(f\"üîç Filtered search: '{query_text}'\")\n",
    "        print(f\"üìã Filters: {filter_str}\")\n",
    "        print(f\"üìä Results: {len(response.objects)}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        results = []\n",
    "        for i, obj in enumerate(response.objects, 1):\n",
    "            distance = obj.metadata.distance\n",
    "            similarity = 1 - distance\n",
    "            \n",
    "            result = {\n",
    "                'rank': i,\n",
    "                'text': obj.properties['text'],\n",
    "                'language': obj.properties['language'],\n",
    "                'category': obj.properties['category'],\n",
    "                'author': obj.properties['author'],\n",
    "                'similarity': similarity\n",
    "            }\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "            print(f\"   {i}. [{result['language'].upper()}] {result['text']}\")\n",
    "            print(f\"      üéØ Similarity: {similarity:.3f} | üìö {result['category']}\")\n",
    "            print()\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during filtered search: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# Demonstrate different filtering scenarios\n",
    "print(\"üéØ Demonstrating filtered semantic search...\\n\")\n",
    "\n",
    "# Example 1: Find music-related content only\n",
    "print(\"Example 1: Music category only\")\n",
    "filtered_semantic_search(\"orchestral compositions\", category_filter=\"music\")\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Example 2: Find French-language content only\n",
    "print(\"Example 2: French language only\")\n",
    "filtered_semantic_search(\"musical works\", language_filter=\"fr\")\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Example 3: Combine filters - English library science content\n",
    "print(\"Example 3: English library science content\")\n",
    "filtered_semantic_search(\"digital collections\", language_filter=\"en\", category_filter=\"library_science\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: Analyzing Search Quality and Performance\n",
    "\n",
    "Let's analyze how well our multilingual embeddings perform for cross-language retrieval. This is crucial for understanding the effectiveness of the semantic search system in real-world applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_cross_language_performance():\n",
    "    \"\"\"Analyze how well the system performs cross-language semantic search.\"\"\"\n",
    "    \n",
    "    if client is None or collection is None:\n",
    "        print(\"‚ö†Ô∏è Cannot perform analysis (Weaviate not connected)\")\n",
    "        return\n",
    "    \n",
    "    # Test queries in different languages for the same concept\n",
    "    cross_language_tests = [\n",
    "        {\n",
    "            \"concept\": \"Schubert Symphony\",\n",
    "            \"queries\": {\n",
    "                \"en\": \"Schubert symphony unfinished\",\n",
    "                \"fr\": \"symphonie Schubert inachev√©e\",\n",
    "                \"de\": \"Schubert Sinfonie unvollendet\",\n",
    "                \"es\": \"sinfon√≠a Schubert inconclusa\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"concept\": \"Digital Libraries\",\n",
    "            \"queries\": {\n",
    "                \"en\": \"digital library technology\",\n",
    "                \"fr\": \"technologie biblioth√®que num√©rique\",\n",
    "                \"de\": \"digitale Bibliothek Technologie\",\n",
    "                \"es\": \"tecnolog√≠a biblioteca digital\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"üìä Cross-Language Retrieval Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for test in cross_language_tests:\n",
    "        print(f\"\\nüéØ Concept: {test['concept']}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Store results for comparison\n",
    "        all_results = {}\n",
    "        \n",
    "        for lang, query in test['queries'].items():\n",
    "            print(f\"\\nüîç Query in {lang.upper()}: '{query}'\")\n",
    "            results = perform_semantic_search(query, limit=3, show_details=False)\n",
    "            all_results[lang] = results\n",
    "            \n",
    "            # Show top result\n",
    "            if results:\n",
    "                top_result = results[0]\n",
    "                print(f\"   ü•á Top result: {top_result['text'][:60]}...\")\n",
    "                print(f\"   üìä Similarity: {top_result['similarity']:.3f} | Language: {top_result['language']}\")\n",
    "            else:\n",
    "                print(\"   ‚ùå No results found\")\n",
    "        \n",
    "        # Analyze consistency across languages\n",
    "        print(f\"\\nüìà Analysis for {test['concept']}:\")\n",
    "        \n",
    "        # Check if different language queries return similar top results\n",
    "        top_texts = [results[0]['text'] if results else None for results in all_results.values()]\n",
    "        similarities = [results[0]['similarity'] if results else 0 for results in all_results.values()]\n",
    "        \n",
    "        print(f\"   üìä Average similarity score: {np.mean(similarities):.3f} (¬±{np.std(similarities):.3f})\")\n",
    "        print(f\"   üéØ Consistency: {'High' if np.std(similarities) < 0.1 else 'Variable'}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Run the cross-language analysis\n",
    "analyze_cross_language_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 11: Adding New Documents Dynamically\n",
    "\n",
    "In real-world applications, you'll need to add new documents to your vector database over time. Let's demonstrate how to extend our collection with additional multilingual content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some new documents to demonstrate dynamic growth\n",
    "new_documents = [\n",
    "    {\n",
    "        \"text\": \"Johann Sebastian Bach: Brandenburg Concerto No. 3 in G major\",\n",
    "        \"language\": \"en\",\n",
    "        \"category\": \"music\",\n",
    "        \"author\": \"Johann Sebastian Bach\",\n",
    "        \"embedding_model\": \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Jean-S√©bastien Bach: Concerto Brandebourgeois n¬∞ 3 en sol majeur\",\n",
    "        \"language\": \"fr\",\n",
    "        \"category\": \"music\", \n",
    "        \"author\": \"Johann Sebastian Bach\",\n",
    "        \"embedding_model\": \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Machine learning algorithms for bibliographic data analysis\",\n",
    "        \"language\": \"en\",\n",
    "        \"category\": \"library_science\",\n",
    "        \"author\": \"Unknown\",\n",
    "        \"embedding_model\": \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Cervantes: Don Quijote de la Mancha - novela espa√±ola\",\n",
    "        \"language\": \"es\",\n",
    "        \"category\": \"literature\",\n",
    "        \"author\": \"Miguel de Cervantes\",\n",
    "        \"embedding_model\": \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "    }\n",
    "]\n",
    "\n",
    "def add_new_documents(documents: List[Dict]) -> int:\n",
    "    \"\"\"Add new documents to the existing collection.\n",
    "    \n",
    "    Args:\n",
    "        documents: List of document dictionaries to add\n",
    "        \n",
    "    Returns:\n",
    "        Number of successfully added documents\n",
    "    \"\"\"\n",
    "    if client is None or collection is None:\n",
    "        print(\"‚ö†Ô∏è Cannot add documents (Weaviate not connected)\")\n",
    "        return 0\n",
    "    \n",
    "    print(f\"üìù Adding {len(documents)} new documents...\")\n",
    "    \n",
    "    # Generate embeddings for new documents\n",
    "    new_texts = [doc[\"text\"] for doc in documents]\n",
    "    new_embeddings = model.encode(new_texts)\n",
    "    \n",
    "    added_count = 0\n",
    "    \n",
    "    try:\n",
    "        with collection.batch.fixed_size(batch_size=100) as batch_writer:\n",
    "            for i, (document, embedding) in enumerate(zip(documents, new_embeddings)):\n",
    "                try:\n",
    "                    # Generate unique UUID\n",
    "                    uuid_input = f\"new_{document['text']}_{document['language']}\"\n",
    "                    uuid = generate_uuid5(uuid_input)\n",
    "                    \n",
    "                    # Convert embedding to list format\n",
    "                    vector_data = embedding.tolist() if hasattr(embedding, 'tolist') else list(embedding)\n",
    "                    \n",
    "                    # Add to collection\n",
    "                    batch_writer.add_object(\n",
    "                        properties=document,\n",
    "                        uuid=uuid,\n",
    "                        vector=vector_data\n",
    "                    )\n",
    "                    \n",
    "                    added_count += 1\n",
    "                    print(f\"   ‚úÖ Added: {document['text'][:50]}... ({document['language']})\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ùå Error adding document {i}: {str(e)}\")\n",
    "        \n",
    "        print(f\"\\nüéâ Successfully added {added_count}/{len(documents)} new documents!\")\n",
    "        \n",
    "        # Show updated collection size\n",
    "        try:\n",
    "            result = collection.aggregate.over_all(total_count=True)\n",
    "            total_objects = result.total_count\n",
    "            print(f\"üìä Collection now contains {total_objects} total objects\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not verify updated object count: {str(e)}\")\n",
    "            \n",
    "        return added_count\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during batch addition: {str(e)}\")\n",
    "        return 0\n",
    "\n",
    "# Add the new documents\n",
    "newly_added = add_new_documents(new_documents)\n",
    "\n",
    "if newly_added > 0:\n",
    "    print(\"\\nüîç Testing search with expanded collection...\")\n",
    "    \n",
    "    # Test a search that should now find Bach content\n",
    "    print(\"\\nSearching for 'Baroque music concerto':\")\n",
    "    perform_semantic_search(\"Baroque music concerto\", limit=3, show_details=True)\n",
    "    \n",
    "    print(\"\\nSearching for 'Spanish literature':\")\n",
    "    perform_semantic_search(\"Spanish literature\", limit=3, show_details=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 12: Performance Considerations and Best Practices\n",
    "\n",
    "Let's explore some important considerations for using multilingual embeddings and vector databases in production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze performance characteristics of our setup\n",
    "import time\n",
    "\n",
    "def benchmark_operations():\n",
    "    \"\"\"Benchmark key operations to understand performance characteristics.\"\"\"\n",
    "    \n",
    "    print(\"‚ö° Performance Benchmarking\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Benchmark 1: Embedding generation speed\n",
    "    test_texts = [\n",
    "        \"Franz Schubert composed many beautiful symphonies\",\n",
    "        \"La musique classique europ√©enne est tr√®s riche\", \n",
    "        \"Deutsche Komponisten haben die Musikgeschichte gepr√§gt\",\n",
    "        \"La literatura espa√±ola incluye muchas obras maestras\",\n",
    "        \"Digital libraries are transforming how we access information\"\n",
    "    ] * 10  # 50 texts total\n",
    "    \n",
    "    start_time = time.time()\n",
    "    embeddings = model.encode(test_texts)\n",
    "    embedding_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"üìä Embedding Generation:\")\n",
    "    print(f\"   Texts processed: {len(test_texts)}\")\n",
    "    print(f\"   Total time: {embedding_time:.3f} seconds\")\n",
    "    print(f\"   Rate: {len(test_texts)/embedding_time:.1f} texts/second\")\n",
    "    print(f\"   Per text: {embedding_time/len(test_texts)*1000:.1f} ms/text\")\n",
    "    \n",
    "    # Benchmark 2: Search performance\n",
    "    if client is not None and collection is not None:\n",
    "        search_queries = [\n",
    "            \"classical music\",\n",
    "            \"French literature\",\n",
    "            \"digital preservation\",\n",
    "            \"baroque compositions\",\n",
    "            \"library technology\"\n",
    "        ]\n",
    "        \n",
    "        search_times = []\n",
    "        for query in search_queries:\n",
    "            start_time = time.time()\n",
    "            perform_semantic_search(query, limit=5, show_details=False)\n",
    "            search_time = time.time() - start_time\n",
    "            search_times.append(search_time)\n",
    "        \n",
    "        avg_search_time = np.mean(search_times)\n",
    "        \n",
    "        print(f\"\\nüîç Search Performance:\")\n",
    "        print(f\"   Queries tested: {len(search_queries)}\")\n",
    "        print(f\"   Average search time: {avg_search_time:.3f} seconds\")\n",
    "        print(f\"   Range: {min(search_times):.3f} - {max(search_times):.3f} seconds\")\n",
    "    \n",
    "    # Memory usage estimation\n",
    "    embedding_size_mb = embeddings.nbytes / 1024 / 1024\n",
    "    print(f\"\\nüíæ Memory Usage:\")\n",
    "    print(f\"   {len(test_texts)} embeddings: {embedding_size_mb:.2f} MB\")\n",
    "    print(f\"   Per embedding: {embeddings.nbytes/len(test_texts)/1024:.1f} KB\")\n",
    "    print(f\"   Estimated for 1M docs: {embedding_size_mb * 1000000 / len(test_texts) / 1024:.1f} GB\")\n",
    "\n",
    "# Run benchmarks\n",
    "benchmark_operations()\n",
    "\n",
    "print(\"\\nüìã Best Practices Summary:\")\n",
    "print(\"=\" * 35)\n",
    "print(\"‚úÖ Batch embedding generation for efficiency\")\n",
    "print(\"‚úÖ Use appropriate vector index parameters (ef, max_connections)\")\n",
    "print(\"‚úÖ Consider embedding caching for frequently used texts\")\n",
    "print(\"‚úÖ Monitor memory usage for large collections\")\n",
    "print(\"‚úÖ Combine semantic search with metadata filtering\")\n",
    "print(\"‚úÖ Regular index optimization for production systems\")\n",
    "print(\"‚úÖ Use consistent UUIDs for idempotent operations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 13: Real-World Application Example\n",
    "\n",
    "Let's put everything together in a practical example that simulates a real-world multilingual library search system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilingualLibrarySearch:\n",
    "    \"\"\"A complete multilingual semantic search system for library catalogs.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = 'paraphrase-multilingual-MiniLM-L12-v2'):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        \n",
    "    def connect_to_weaviate(self, host: str = \"localhost\", port: int = 8080):\n",
    "        \"\"\"Connect to Weaviate database.\"\"\"\n",
    "        try:\n",
    "            from weaviate.connect import ConnectionParams\n",
    "            connection_params = ConnectionParams.from_params(\n",
    "                http_host=host, http_port=port, http_secure=False,\n",
    "                grpc_host=host, grpc_port=50051, grpc_secure=False\n",
    "            )\n",
    "            self.client = weaviate.WeaviateClient(connection_params=connection_params)\n",
    "            self.client.connect()\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Connection failed: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def search_catalog(self, query: str, language: str = None, \n",
    "                      category: str = None, limit: int = 5) -> List[Dict]:\n",
    "        \"\"\"Search the library catalog with optional filters.\n",
    "        \n",
    "        Args:\n",
    "            query: Search query in any supported language\n",
    "            language: Optional language filter (en, fr, de, es, etc.)\n",
    "            category: Optional category filter (music, literature, library_science)\n",
    "            limit: Maximum number of results\n",
    "            \n",
    "        Returns:\n",
    "            List of search results with relevance scores\n",
    "        \"\"\"\n",
    "        if not self.client or not self.collection:\n",
    "            return []\n",
    "        \n",
    "        # Generate query embedding\n",
    "        query_embedding = self.model.encode([query])[0]\n",
    "        \n",
    "        # Build search with optional filters\n",
    "        search_query = self.collection.query.near_vector(\n",
    "            near_vector=query_embedding.tolist(),\n",
    "            limit=limit,\n",
    "            return_metadata=['distance']\n",
    "        )\n",
    "        \n",
    "        # Apply filters if specified\n",
    "        if language or category:\n",
    "            from weaviate.classes.query import Filter\n",
    "            filters = []\n",
    "            if language:\n",
    "                filters.append(Filter.by_property(\"language\").equal(language))\n",
    "            if category:\n",
    "                filters.append(Filter.by_property(\"category\").equal(category))\n",
    "            \n",
    "            combined_filter = filters[0] if len(filters) == 1 else Filter.all_of(filters)\n",
    "            search_query = search_query.where(combined_filter)\n",
    "        \n",
    "        # Execute search\n",
    "        response = search_query\n",
    "        \n",
    "        # Format results\n",
    "        results = []\n",
    "        for obj in response.objects:\n",
    "            similarity = 1 - obj.metadata.distance\n",
    "            results.append({\n",
    "                'title': obj.properties['text'],\n",
    "                'author': obj.properties['author'],\n",
    "                'language': obj.properties['language'],\n",
    "                'category': obj.properties['category'],\n",
    "                'relevance': similarity\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def format_search_results(self, results: List[Dict], query: str) -> str:\n",
    "        \"\"\"Format search results for display.\"\"\"\n",
    "        if not results:\n",
    "            return f\"No results found for: '{query}'\"\n",
    "        \n",
    "        output = [f\"\\nüîç Search results for: '{query}'\"]\n",
    "        output.append(\"=\" * 50)\n",
    "        \n",
    "        for i, result in enumerate(results, 1):\n",
    "            relevance_bar = \"‚ñà\" * int(result['relevance'] * 10) + \"‚ñë\" * (10 - int(result['relevance'] * 10))\n",
    "            output.append(f\"\\n{i}. {result['title']}\")\n",
    "            output.append(f\"   üë§ {result['author']} | üåç {result['language'].upper()} | üìö {result['category']}\")\n",
    "            output.append(f\"   üìä Relevance: {relevance_bar} {result['relevance']:.3f}\")\n",
    "        \n",
    "        return \"\\n\".join(output)\n",
    "\n",
    "# Create and test the search system\n",
    "print(\"üöÄ Creating Multilingual Library Search System...\")\n",
    "search_system = MultilingualLibrarySearch()\n",
    "\n",
    "if client is not None:\n",
    "    # Use existing connection and collection\n",
    "    search_system.client = client\n",
    "    search_system.collection = collection\n",
    "    \n",
    "    # Test the complete system with various queries\n",
    "    test_scenarios = [\n",
    "        {\"query\": \"m√∫sica cl√°sica\", \"description\": \"Spanish query for classical music\"},\n",
    "        {\"query\": \"biblioth√®que num√©rique\", \"description\": \"French query for digital library\"},\n",
    "        {\"query\": \"Shakespeare drama\", \"language\": \"en\", \"description\": \"English literature search\"},\n",
    "        {\"query\": \"artificial intelligence\", \"category\": \"library_science\", \"description\": \"AI in library science\"},\n",
    "    ]\n",
    "    \n",
    "    for scenario in test_scenarios:\n",
    "        print(f\"\\nüìñ Test: {scenario['description']}\")\n",
    "        \n",
    "        # Extract search parameters\n",
    "        query = scenario['query']\n",
    "        language = scenario.get('language')\n",
    "        category = scenario.get('category')\n",
    "        \n",
    "        # Perform search\n",
    "        results = search_system.search_catalog(query, language, category, limit=3)\n",
    "        \n",
    "        # Display formatted results\n",
    "        print(search_system.format_search_results(results, query))\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Weaviate not connected - search system created but not tested\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Next Steps\n",
    "\n",
    "Congratulations! You've successfully built a complete multilingual semantic search system using sentence transformers and Weaviate. Here's what you've accomplished:\n",
    "\n",
    "### üéØ Key Achievements\n",
    "\n",
    "1. **Understanding Embeddings**: You learned how text gets converted into numerical vectors that capture semantic meaning\n",
    "2. **Cross-Language Similarity**: You demonstrated how multilingual models understand concepts across different languages\n",
    "3. **Vector Database Setup**: You configured Weaviate for efficient similarity search at scale\n",
    "4. **Semantic Indexing**: You indexed documents with their embeddings for fast retrieval\n",
    "5. **Advanced Querying**: You combined semantic similarity with metadata filtering\n",
    "6. **Performance Analysis**: You benchmarked operations and understood scalability considerations\n",
    "7. **Production System**: You built a complete library search system ready for real-world use\n",
    "\n",
    "### üöÄ Next Steps for Further Learning\n",
    "\n",
    "1. **Experiment with Different Models**: Try other sentence transformers like `all-mpnet-base-v2` or `all-multilingual-distilbert-base-v1`\n",
    "2. **Larger Collections**: Test with thousands or millions of documents to understand scaling behavior\n",
    "3. **Custom Fine-tuning**: Adapt models to your specific domain using techniques like SetFit\n",
    "4. **Hybrid Search**: Combine vector similarity with traditional keyword search (BM25)\n",
    "5. **Real-time Updates**: Implement systems that handle continuous document ingestion\n",
    "6. **Evaluation Metrics**: Develop systematic approaches to measure search quality\n",
    "7. **Production Deployment**: Scale to cloud environments with proper monitoring and optimization\n",
    "\n",
    "### üí° Remember These Key Insights\n",
    "\n",
    "- **Embeddings capture meaning, not just words** - Similar concepts cluster together regardless of language\n",
    "- **Vector databases enable semantic search at scale** - Sub-second queries across millions of documents\n",
    "- **Filtering enhances semantic search** - Combine meaning-based similarity with structured metadata\n",
    "- **Batch operations improve efficiency** - Process multiple items together for better performance\n",
    "- **Quality depends on your data** - Good embeddings require good input text\n",
    "\n",
    "You now have the foundation to build sophisticated multilingual search systems that can understand meaning across languages and domains. The techniques you've learned apply to many fields beyond libraries - from e-commerce to research to customer support.\n",
    "\n",
    "Happy searching! üîç‚ú®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up resources\n",
    "if client is not None:\n",
    "    try:\n",
    "        client.close()\n",
    "        print(\"‚úÖ Weaviate connection closed successfully\")\n",
    "    except:\n",
    "        print(\"‚ÑπÔ∏è Connection cleanup completed\")\n",
    "\n",
    "print(\"\\nüéâ Tutorial completed successfully!\")\n",
    "print(\"üìö You're now ready to build multilingual semantic search systems\")\n",
    "print(\"üöÄ Consider exploring the suggested next steps for advanced applications\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
